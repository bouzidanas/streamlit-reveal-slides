{"ast":null,"code":"import _toConsumableArray from \"/home/anasbouzid/streamlit-reveal-slides/reveal_slides/frontend/node_modules/@babel/runtime/helpers/esm/toConsumableArray.js\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nimport { Schema, Field } from '../../schema';\nimport { Dictionary, Utf8, Binary, Decimal, FixedSizeBinary, List, FixedSizeList, Map_, Struct, Union, Bool, Null, Int, Float, Date_, Time, Interval, Timestamp, Int32 } from '../../type';\nimport { DictionaryBatch, RecordBatch, FieldNode, BufferRegion } from './message';\nimport { TimeUnit, Precision, IntervalUnit, UnionMode, DateUnit } from '../../enum';\n/** @ignore */\nexport function schemaFromJSON(_schema) {\n  var dictionaries = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : new Map();\n  return new Schema(schemaFieldsFromJSON(_schema, dictionaries), customMetadataFromJSON(_schema['customMetadata']), dictionaries);\n}\n/** @ignore */\nexport function recordBatchFromJSON(b) {\n  return new RecordBatch(b['count'], fieldNodesFromJSON(b['columns']), buffersFromJSON(b['columns']));\n}\n/** @ignore */\nexport function dictionaryBatchFromJSON(b) {\n  return new DictionaryBatch(recordBatchFromJSON(b['data']), b['id'], b['isDelta']);\n}\n/** @ignore */\nfunction schemaFieldsFromJSON(_schema, dictionaries) {\n  return (_schema['fields'] || []).filter(Boolean).map(function (f) {\n    return Field.fromJSON(f, dictionaries);\n  });\n}\n/** @ignore */\nfunction fieldChildrenFromJSON(_field, dictionaries) {\n  return (_field['children'] || []).filter(Boolean).map(function (f) {\n    return Field.fromJSON(f, dictionaries);\n  });\n}\n/** @ignore */\nfunction fieldNodesFromJSON(xs) {\n  return (xs || []).reduce(function (fieldNodes, column) {\n    return [].concat(_toConsumableArray(fieldNodes), [new FieldNode(column['count'], nullCountFromJSON(column['VALIDITY']))], _toConsumableArray(fieldNodesFromJSON(column['children'])));\n  }, []);\n}\n/** @ignore */\nfunction buffersFromJSON(xs) {\n  var buffers = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];\n  for (var i = -1, n = (xs || []).length; ++i < n;) {\n    var column = xs[i];\n    column['VALIDITY'] && buffers.push(new BufferRegion(buffers.length, column['VALIDITY'].length));\n    column['TYPE'] && buffers.push(new BufferRegion(buffers.length, column['TYPE'].length));\n    column['OFFSET'] && buffers.push(new BufferRegion(buffers.length, column['OFFSET'].length));\n    column['DATA'] && buffers.push(new BufferRegion(buffers.length, column['DATA'].length));\n    buffers = buffersFromJSON(column['children'], buffers);\n  }\n  return buffers;\n}\n/** @ignore */\nfunction nullCountFromJSON(validity) {\n  return (validity || []).reduce(function (sum, val) {\n    return sum + +(val === 0);\n  }, 0);\n}\n/** @ignore */\nexport function fieldFromJSON(_field, dictionaries) {\n  var id;\n  var keys;\n  var field;\n  var dictMeta;\n  var type;\n  var dictType;\n  // If no dictionary encoding\n  if (!dictionaries || !(dictMeta = _field['dictionary'])) {\n    type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries));\n    field = new Field(_field['name'], type, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n  }\n  // tslint:disable\n  // If dictionary encoded and the first time we've seen this dictionary id, decode\n  // the data type and child fields, then wrap in a Dictionary type and insert the\n  // data type into the dictionary types map.\n  else if (!dictionaries.has(id = dictMeta['id'])) {\n    // a dictionary index defaults to signed 32 bit int if unspecified\n    keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) : new Int32();\n    dictionaries.set(id, type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries)));\n    dictType = new Dictionary(type, keys, id, dictMeta['isOrdered']);\n    field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n  }\n  // If dictionary encoded, and have already seen this dictionary Id in the schema, then reuse the\n  // data type and wrap in a new Dictionary type and field.\n  else {\n    // a dictionary index defaults to signed 32 bit int if unspecified\n    keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) : new Int32();\n    dictType = new Dictionary(dictionaries.get(id), keys, id, dictMeta['isOrdered']);\n    field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n  }\n  return field || null;\n}\n/** @ignore */\nfunction customMetadataFromJSON(_metadata) {\n  return new Map(Object.entries(_metadata || {}));\n}\n/** @ignore */\nfunction indexTypeFromJSON(_type) {\n  return new Int(_type['isSigned'], _type['bitWidth']);\n}\n/** @ignore */\nfunction typeFromJSON(f, children) {\n  var typeId = f['type']['name'];\n  switch (typeId) {\n    case 'NONE':\n      return new Null();\n    case 'null':\n      return new Null();\n    case 'binary':\n      return new Binary();\n    case 'utf8':\n      return new Utf8();\n    case 'bool':\n      return new Bool();\n    case 'list':\n      return new List((children || [])[0]);\n    case 'struct':\n      return new Struct(children || []);\n    case 'struct_':\n      return new Struct(children || []);\n  }\n  switch (typeId) {\n    case 'int':\n      {\n        var t = f['type'];\n        return new Int(t['isSigned'], t['bitWidth']);\n      }\n    case 'floatingpoint':\n      {\n        var _t = f['type'];\n        return new Float(Precision[_t['precision']]);\n      }\n    case 'decimal':\n      {\n        var _t2 = f['type'];\n        return new Decimal(_t2['scale'], _t2['precision']);\n      }\n    case 'date':\n      {\n        var _t3 = f['type'];\n        return new Date_(DateUnit[_t3['unit']]);\n      }\n    case 'time':\n      {\n        var _t4 = f['type'];\n        return new Time(TimeUnit[_t4['unit']], _t4['bitWidth']);\n      }\n    case 'timestamp':\n      {\n        var _t5 = f['type'];\n        return new Timestamp(TimeUnit[_t5['unit']], _t5['timezone']);\n      }\n    case 'interval':\n      {\n        var _t6 = f['type'];\n        return new Interval(IntervalUnit[_t6['unit']]);\n      }\n    case 'union':\n      {\n        var _t7 = f['type'];\n        return new Union(UnionMode[_t7['mode']], _t7['typeIds'] || [], children || []);\n      }\n    case 'fixedsizebinary':\n      {\n        var _t8 = f['type'];\n        return new FixedSizeBinary(_t8['byteWidth']);\n      }\n    case 'fixedsizelist':\n      {\n        var _t9 = f['type'];\n        return new FixedSizeList(_t9['listSize'], (children || [])[0]);\n      }\n    case 'map':\n      {\n        var _t10 = f['type'];\n        return new Map_((children || [])[0], _t10['keysSorted']);\n      }\n  }\n  throw new Error(\"Unrecognized type: \\\"\".concat(typeId, \"\\\"\"));\n}","map":{"version":3,"names":["Schema","Field","Dictionary","Utf8","Binary","Decimal","FixedSizeBinary","List","FixedSizeList","Map_","Struct","Union","Bool","Null","Int","Float","Date_","Time","Interval","Timestamp","Int32","DictionaryBatch","RecordBatch","FieldNode","BufferRegion","TimeUnit","Precision","IntervalUnit","UnionMode","DateUnit","schemaFromJSON","_schema","dictionaries","arguments","length","undefined","Map","schemaFieldsFromJSON","customMetadataFromJSON","recordBatchFromJSON","b","fieldNodesFromJSON","buffersFromJSON","dictionaryBatchFromJSON","filter","Boolean","map","f","fromJSON","fieldChildrenFromJSON","_field","xs","reduce","fieldNodes","column","concat","_toConsumableArray","nullCountFromJSON","buffers","i","n","push","validity","sum","val","fieldFromJSON","id","keys","field","dictMeta","type","dictType","typeFromJSON","has","indexTypeFromJSON","set","get","_metadata","Object","entries","_type","children","typeId","t","Error"],"sources":["ipc/metadata/json.ts"],"sourcesContent":["// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\nimport { Schema, Field } from '../../schema';\nimport {\n    DataType, Dictionary, TimeBitWidth,\n    Utf8, Binary, Decimal, FixedSizeBinary,\n    List, FixedSizeList, Map_, Struct, Union,\n    Bool, Null, Int, Float, Date_, Time, Interval, Timestamp, IntBitWidth, Int32, TKeys,\n} from '../../type';\n\nimport { DictionaryBatch, RecordBatch, FieldNode, BufferRegion } from './message';\nimport { TimeUnit, Precision, IntervalUnit, UnionMode, DateUnit } from '../../enum';\n\n/** @ignore */\nexport function schemaFromJSON(_schema: any, dictionaries: Map<number, DataType> = new Map()) {\n    return new Schema(\n        schemaFieldsFromJSON(_schema, dictionaries),\n        customMetadataFromJSON(_schema['customMetadata']),\n        dictionaries\n    );\n}\n\n/** @ignore */\nexport function recordBatchFromJSON(b: any) {\n    return new RecordBatch(\n        b['count'],\n        fieldNodesFromJSON(b['columns']),\n        buffersFromJSON(b['columns'])\n    );\n}\n\n/** @ignore */\nexport function dictionaryBatchFromJSON(b: any) {\n    return new DictionaryBatch(\n        recordBatchFromJSON(b['data']),\n        b['id'], b['isDelta']\n    );\n}\n\n/** @ignore */\nfunction schemaFieldsFromJSON(_schema: any, dictionaries?: Map<number, DataType>) {\n    return (_schema['fields'] || []).filter(Boolean).map((f: any) => Field.fromJSON(f, dictionaries));\n}\n\n/** @ignore */\nfunction fieldChildrenFromJSON(_field: any, dictionaries?: Map<number, DataType>): Field[] {\n    return (_field['children'] || []).filter(Boolean).map((f: any) => Field.fromJSON(f, dictionaries));\n}\n\n/** @ignore */\nfunction fieldNodesFromJSON(xs: any[]): FieldNode[] {\n    return (xs || []).reduce<FieldNode[]>((fieldNodes, column: any) => [\n        ...fieldNodes,\n        new FieldNode(\n            column['count'],\n            nullCountFromJSON(column['VALIDITY'])\n        ),\n        ...fieldNodesFromJSON(column['children'])\n    ], [] as FieldNode[]);\n}\n\n/** @ignore */\nfunction buffersFromJSON(xs: any[], buffers: BufferRegion[] = []): BufferRegion[] {\n    for (let i = -1, n = (xs || []).length; ++i < n;) {\n        const column = xs[i];\n        column['VALIDITY'] && buffers.push(new BufferRegion(buffers.length, column['VALIDITY'].length));\n        column['TYPE'] && buffers.push(new BufferRegion(buffers.length, column['TYPE'].length));\n        column['OFFSET'] && buffers.push(new BufferRegion(buffers.length, column['OFFSET'].length));\n        column['DATA'] && buffers.push(new BufferRegion(buffers.length, column['DATA'].length));\n        buffers = buffersFromJSON(column['children'], buffers);\n    }\n    return buffers;\n}\n\n/** @ignore */\nfunction nullCountFromJSON(validity: number[]) {\n    return (validity || []).reduce((sum, val) => sum + +(val === 0), 0);\n}\n\n/** @ignore */\nexport function fieldFromJSON(_field: any, dictionaries?: Map<number, DataType>) {\n\n    let id: number;\n    let keys: TKeys | null;\n    let field: Field | void;\n    let dictMeta: any;\n    let type: DataType<any>;\n    let dictType: Dictionary;\n\n    // If no dictionary encoding\n    if (!dictionaries || !(dictMeta = _field['dictionary'])) {\n        type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries));\n        field = new Field(_field['name'], type, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    // tslint:disable\n    // If dictionary encoded and the first time we've seen this dictionary id, decode\n    // the data type and child fields, then wrap in a Dictionary type and insert the\n    // data type into the dictionary types map.\n    else if (!dictionaries.has(id = dictMeta['id'])) {\n        // a dictionary index defaults to signed 32 bit int if unspecified\n        keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) as TKeys : new Int32();\n        dictionaries.set(id, type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries)));\n        dictType = new Dictionary(type, keys, id, dictMeta['isOrdered']);\n        field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    // If dictionary encoded, and have already seen this dictionary Id in the schema, then reuse the\n    // data type and wrap in a new Dictionary type and field.\n    else {\n        // a dictionary index defaults to signed 32 bit int if unspecified\n        keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) as TKeys : new Int32();\n        dictType = new Dictionary(dictionaries.get(id)!, keys, id, dictMeta['isOrdered']);\n        field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    return field || null;\n}\n\n/** @ignore */\nfunction customMetadataFromJSON(_metadata?: object) {\n    return new Map<string, string>(Object.entries(_metadata || {}));\n}\n\n/** @ignore */\nfunction indexTypeFromJSON(_type: any) {\n    return new Int(_type['isSigned'], _type['bitWidth']);\n}\n\n/** @ignore */\nfunction typeFromJSON(f: any, children?: Field[]): DataType<any> {\n\n    const typeId = f['type']['name'];\n\n    switch (typeId) {\n        case 'NONE':   return new Null();\n        case 'null':   return new Null();\n        case 'binary': return new Binary();\n        case 'utf8':   return new Utf8();\n        case 'bool':   return new Bool();\n        case 'list':   return new List((children || [])[0]);\n        case 'struct': return new Struct(children || []);\n        case 'struct_': return new Struct(children || []);\n    }\n\n    switch (typeId) {\n        case 'int': {\n            const t = f['type'];\n            return new Int(t['isSigned'], t['bitWidth'] as IntBitWidth);\n        }\n        case 'floatingpoint': {\n            const t = f['type'];\n            return new Float(Precision[t['precision']] as any);\n        }\n        case 'decimal': {\n            const t = f['type'];\n            return new Decimal(t['scale'], t['precision']);\n        }\n        case 'date': {\n            const t = f['type'];\n            return new Date_(DateUnit[t['unit']] as any);\n        }\n        case 'time': {\n            const t = f['type'];\n            return new Time(TimeUnit[t['unit']] as any, t['bitWidth'] as TimeBitWidth);\n        }\n        case 'timestamp': {\n            const t = f['type'];\n            return new Timestamp(TimeUnit[t['unit']] as any, t['timezone']);\n        }\n        case 'interval': {\n            const t = f['type'];\n            return new Interval(IntervalUnit[t['unit']] as any);\n        }\n        case 'union': {\n            const t = f['type'];\n            return new Union(UnionMode[t['mode']] as any, (t['typeIds'] || []), children || []);\n        }\n        case 'fixedsizebinary': {\n            const t = f['type'];\n            return new FixedSizeBinary(t['byteWidth']);\n        }\n        case 'fixedsizelist': {\n            const t = f['type'];\n            return new FixedSizeList(t['listSize'], (children || [])[0]);\n        }\n        case 'map': {\n            const t = f['type'];\n            return new Map_((children || [])[0], t['keysSorted']);\n        }\n    }\n    throw new Error(`Unrecognized type: \"${typeId}\"`);\n}\n"],"mappings":";AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,SAASA,MAAM,EAAEC,KAAK,QAAQ,cAAc;AAC5C,SACcC,UAAU,EACpBC,IAAI,EAAEC,MAAM,EAAEC,OAAO,EAAEC,eAAe,EACtCC,IAAI,EAAEC,aAAa,EAAEC,IAAI,EAAEC,MAAM,EAAEC,KAAK,EACxCC,IAAI,EAAEC,IAAI,EAAEC,GAAG,EAAEC,KAAK,EAAEC,KAAK,EAAEC,IAAI,EAAEC,QAAQ,EAAEC,SAAS,EAAeC,KAAK,QACzE,YAAY;AAEnB,SAASC,eAAe,EAAEC,WAAW,EAAEC,SAAS,EAAEC,YAAY,QAAQ,WAAW;AACjF,SAASC,QAAQ,EAAEC,SAAS,EAAEC,YAAY,EAAEC,SAAS,EAAEC,QAAQ,QAAQ,YAAY;AAEnF;AACA,OAAM,SAAUC,cAAcA,CAACC,OAAY,EAAiD;EAAA,IAA/CC,YAAA,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAsC,IAAIG,GAAG,EAAE;EACxF,OAAO,IAAIpC,MAAM,CACbqC,oBAAoB,CAACN,OAAO,EAAEC,YAAY,CAAC,EAC3CM,sBAAsB,CAACP,OAAO,CAAC,gBAAgB,CAAC,CAAC,EACjDC,YAAY,CACf;AACL;AAEA;AACA,OAAM,SAAUO,mBAAmBA,CAACC,CAAM;EACtC,OAAO,IAAIlB,WAAW,CAClBkB,CAAC,CAAC,OAAO,CAAC,EACVC,kBAAkB,CAACD,CAAC,CAAC,SAAS,CAAC,CAAC,EAChCE,eAAe,CAACF,CAAC,CAAC,SAAS,CAAC,CAAC,CAChC;AACL;AAEA;AACA,OAAM,SAAUG,uBAAuBA,CAACH,CAAM;EAC1C,OAAO,IAAInB,eAAe,CACtBkB,mBAAmB,CAACC,CAAC,CAAC,MAAM,CAAC,CAAC,EAC9BA,CAAC,CAAC,IAAI,CAAC,EAAEA,CAAC,CAAC,SAAS,CAAC,CACxB;AACL;AAEA;AACA,SAASH,oBAAoBA,CAACN,OAAY,EAAEC,YAAoC;EAC5E,OAAO,CAACD,OAAO,CAAC,QAAQ,CAAC,IAAI,EAAE,EAAEa,MAAM,CAACC,OAAO,CAAC,CAACC,GAAG,CAAC,UAACC,CAAM;IAAA,OAAK9C,KAAK,CAAC+C,QAAQ,CAACD,CAAC,EAAEf,YAAY,CAAC;EAAA,EAAC;AACrG;AAEA;AACA,SAASiB,qBAAqBA,CAACC,MAAW,EAAElB,YAAoC;EAC5E,OAAO,CAACkB,MAAM,CAAC,UAAU,CAAC,IAAI,EAAE,EAAEN,MAAM,CAACC,OAAO,CAAC,CAACC,GAAG,CAAC,UAACC,CAAM;IAAA,OAAK9C,KAAK,CAAC+C,QAAQ,CAACD,CAAC,EAAEf,YAAY,CAAC;EAAA,EAAC;AACtG;AAEA;AACA,SAASS,kBAAkBA,CAACU,EAAS;EACjC,OAAO,CAACA,EAAE,IAAI,EAAE,EAAEC,MAAM,CAAc,UAACC,UAAU,EAAEC,MAAW;IAAA,UAAAC,MAAA,CAAAC,kBAAA,CACvDH,UAAU,IACb,IAAI9B,SAAS,CACT+B,MAAM,CAAC,OAAO,CAAC,EACfG,iBAAiB,CAACH,MAAM,CAAC,UAAU,CAAC,CAAC,CACxC,GAAAE,kBAAA,CACEf,kBAAkB,CAACa,MAAM,CAAC,UAAU,CAAC,CAAC;EAAA,CAC5C,EAAE,EAAiB,CAAC;AACzB;AAEA;AACA,SAASZ,eAAeA,CAACS,EAAS,EAA8B;EAAA,IAA5BO,OAAA,GAAAzB,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAA0B,EAAE;EAC5D,KAAK,IAAI0B,CAAC,GAAG,CAAC,CAAC,EAAEC,CAAC,GAAG,CAACT,EAAE,IAAI,EAAE,EAAEjB,MAAM,EAAE,EAAEyB,CAAC,GAAGC,CAAC,GAAG;IAC9C,IAAMN,MAAM,GAAGH,EAAE,CAACQ,CAAC,CAAC;IACpBL,MAAM,CAAC,UAAU,CAAC,IAAII,OAAO,CAACG,IAAI,CAAC,IAAIrC,YAAY,CAACkC,OAAO,CAACxB,MAAM,EAAEoB,MAAM,CAAC,UAAU,CAAC,CAACpB,MAAM,CAAC,CAAC;IAC/FoB,MAAM,CAAC,MAAM,CAAC,IAAII,OAAO,CAACG,IAAI,CAAC,IAAIrC,YAAY,CAACkC,OAAO,CAACxB,MAAM,EAAEoB,MAAM,CAAC,MAAM,CAAC,CAACpB,MAAM,CAAC,CAAC;IACvFoB,MAAM,CAAC,QAAQ,CAAC,IAAII,OAAO,CAACG,IAAI,CAAC,IAAIrC,YAAY,CAACkC,OAAO,CAACxB,MAAM,EAAEoB,MAAM,CAAC,QAAQ,CAAC,CAACpB,MAAM,CAAC,CAAC;IAC3FoB,MAAM,CAAC,MAAM,CAAC,IAAII,OAAO,CAACG,IAAI,CAAC,IAAIrC,YAAY,CAACkC,OAAO,CAACxB,MAAM,EAAEoB,MAAM,CAAC,MAAM,CAAC,CAACpB,MAAM,CAAC,CAAC;IACvFwB,OAAO,GAAGhB,eAAe,CAACY,MAAM,CAAC,UAAU,CAAC,EAAEI,OAAO,CAAC;;EAE1D,OAAOA,OAAO;AAClB;AAEA;AACA,SAASD,iBAAiBA,CAACK,QAAkB;EACzC,OAAO,CAACA,QAAQ,IAAI,EAAE,EAAEV,MAAM,CAAC,UAACW,GAAG,EAAEC,GAAG;IAAA,OAAKD,GAAG,GAAG,EAAEC,GAAG,KAAK,CAAC,CAAC;EAAA,GAAE,CAAC,CAAC;AACvE;AAEA;AACA,OAAM,SAAUC,aAAaA,CAACf,MAAW,EAAElB,YAAoC;EAE3E,IAAIkC,EAAU;EACd,IAAIC,IAAkB;EACtB,IAAIC,KAAmB;EACvB,IAAIC,QAAa;EACjB,IAAIC,IAAmB;EACvB,IAAIC,QAAoB;EAExB;EACA,IAAI,CAACvC,YAAY,IAAI,EAAEqC,QAAQ,GAAGnB,MAAM,CAAC,YAAY,CAAC,CAAC,EAAE;IACrDoB,IAAI,GAAGE,YAAY,CAACtB,MAAM,EAAED,qBAAqB,CAACC,MAAM,EAAElB,YAAY,CAAC,CAAC;IACxEoC,KAAK,GAAG,IAAInE,KAAK,CAACiD,MAAM,CAAC,MAAM,CAAC,EAAEoB,IAAI,EAAEpB,MAAM,CAAC,UAAU,CAAC,EAAEZ,sBAAsB,CAACY,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC;;EAEjH;EACA;EACA;EACA;EAAA,KACK,IAAI,CAAClB,YAAY,CAACyC,GAAG,CAACP,EAAE,GAAGG,QAAQ,CAAC,IAAI,CAAC,CAAC,EAAE;IAC7C;IACAF,IAAI,GAAG,CAACA,IAAI,GAAGE,QAAQ,CAAC,WAAW,CAAC,IAAIK,iBAAiB,CAACP,IAAI,CAAU,GAAG,IAAI/C,KAAK,EAAE;IACtFY,YAAY,CAAC2C,GAAG,CAACT,EAAE,EAAEI,IAAI,GAAGE,YAAY,CAACtB,MAAM,EAAED,qBAAqB,CAACC,MAAM,EAAElB,YAAY,CAAC,CAAC,CAAC;IAC9FuC,QAAQ,GAAG,IAAIrE,UAAU,CAACoE,IAAI,EAAEH,IAAI,EAAED,EAAE,EAAEG,QAAQ,CAAC,WAAW,CAAC,CAAC;IAChED,KAAK,GAAG,IAAInE,KAAK,CAACiD,MAAM,CAAC,MAAM,CAAC,EAAEqB,QAAQ,EAAErB,MAAM,CAAC,UAAU,CAAC,EAAEZ,sBAAsB,CAACY,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC;;EAErH;EACA;EAAA,KACK;IACD;IACAiB,IAAI,GAAG,CAACA,IAAI,GAAGE,QAAQ,CAAC,WAAW,CAAC,IAAIK,iBAAiB,CAACP,IAAI,CAAU,GAAG,IAAI/C,KAAK,EAAE;IACtFmD,QAAQ,GAAG,IAAIrE,UAAU,CAAC8B,YAAY,CAAC4C,GAAG,CAACV,EAAE,CAAE,EAAEC,IAAI,EAAED,EAAE,EAAEG,QAAQ,CAAC,WAAW,CAAC,CAAC;IACjFD,KAAK,GAAG,IAAInE,KAAK,CAACiD,MAAM,CAAC,MAAM,CAAC,EAAEqB,QAAQ,EAAErB,MAAM,CAAC,UAAU,CAAC,EAAEZ,sBAAsB,CAACY,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC;;EAErH,OAAOkB,KAAK,IAAI,IAAI;AACxB;AAEA;AACA,SAAS9B,sBAAsBA,CAACuC,SAAkB;EAC9C,OAAO,IAAIzC,GAAG,CAAiB0C,MAAM,CAACC,OAAO,CAACF,SAAS,IAAI,EAAE,CAAC,CAAC;AACnE;AAEA;AACA,SAASH,iBAAiBA,CAACM,KAAU;EACjC,OAAO,IAAIlE,GAAG,CAACkE,KAAK,CAAC,UAAU,CAAC,EAAEA,KAAK,CAAC,UAAU,CAAC,CAAC;AACxD;AAEA;AACA,SAASR,YAAYA,CAACzB,CAAM,EAAEkC,QAAkB;EAE5C,IAAMC,MAAM,GAAGnC,CAAC,CAAC,MAAM,CAAC,CAAC,MAAM,CAAC;EAEhC,QAAQmC,MAAM;IACV,KAAK,MAAM;MAAI,OAAO,IAAIrE,IAAI,EAAE;IAChC,KAAK,MAAM;MAAI,OAAO,IAAIA,IAAI,EAAE;IAChC,KAAK,QAAQ;MAAE,OAAO,IAAIT,MAAM,EAAE;IAClC,KAAK,MAAM;MAAI,OAAO,IAAID,IAAI,EAAE;IAChC,KAAK,MAAM;MAAI,OAAO,IAAIS,IAAI,EAAE;IAChC,KAAK,MAAM;MAAI,OAAO,IAAIL,IAAI,CAAC,CAAC0E,QAAQ,IAAI,EAAE,EAAE,CAAC,CAAC,CAAC;IACnD,KAAK,QAAQ;MAAE,OAAO,IAAIvE,MAAM,CAACuE,QAAQ,IAAI,EAAE,CAAC;IAChD,KAAK,SAAS;MAAE,OAAO,IAAIvE,MAAM,CAACuE,QAAQ,IAAI,EAAE,CAAC;;EAGrD,QAAQC,MAAM;IACV,KAAK,KAAK;MAAE;QACR,IAAMC,CAAC,GAAGpC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAIjC,GAAG,CAACqE,CAAC,CAAC,UAAU,CAAC,EAAEA,CAAC,CAAC,UAAU,CAAgB,CAAC;;IAE/D,KAAK,eAAe;MAAE;QAClB,IAAMA,EAAC,GAAGpC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAIhC,KAAK,CAACW,SAAS,CAACyD,EAAC,CAAC,WAAW,CAAC,CAAQ,CAAC;;IAEtD,KAAK,SAAS;MAAE;QACZ,IAAMA,GAAC,GAAGpC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI1C,OAAO,CAAC8E,GAAC,CAAC,OAAO,CAAC,EAAEA,GAAC,CAAC,WAAW,CAAC,CAAC;;IAElD,KAAK,MAAM;MAAE;QACT,IAAMA,GAAC,GAAGpC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI/B,KAAK,CAACa,QAAQ,CAACsD,GAAC,CAAC,MAAM,CAAC,CAAQ,CAAC;;IAEhD,KAAK,MAAM;MAAE;QACT,IAAMA,GAAC,GAAGpC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI9B,IAAI,CAACQ,QAAQ,CAAC0D,GAAC,CAAC,MAAM,CAAC,CAAQ,EAAEA,GAAC,CAAC,UAAU,CAAiB,CAAC;;IAE9E,KAAK,WAAW;MAAE;QACd,IAAMA,GAAC,GAAGpC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI5B,SAAS,CAACM,QAAQ,CAAC0D,GAAC,CAAC,MAAM,CAAC,CAAQ,EAAEA,GAAC,CAAC,UAAU,CAAC,CAAC;;IAEnE,KAAK,UAAU;MAAE;QACb,IAAMA,GAAC,GAAGpC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI7B,QAAQ,CAACS,YAAY,CAACwD,GAAC,CAAC,MAAM,CAAC,CAAQ,CAAC;;IAEvD,KAAK,OAAO;MAAE;QACV,IAAMA,GAAC,GAAGpC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAIpC,KAAK,CAACiB,SAAS,CAACuD,GAAC,CAAC,MAAM,CAAC,CAAQ,EAAGA,GAAC,CAAC,SAAS,CAAC,IAAI,EAAE,EAAGF,QAAQ,IAAI,EAAE,CAAC;;IAEvF,KAAK,iBAAiB;MAAE;QACpB,IAAME,GAAC,GAAGpC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAIzC,eAAe,CAAC6E,GAAC,CAAC,WAAW,CAAC,CAAC;;IAE9C,KAAK,eAAe;MAAE;QAClB,IAAMA,GAAC,GAAGpC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAIvC,aAAa,CAAC2E,GAAC,CAAC,UAAU,CAAC,EAAE,CAACF,QAAQ,IAAI,EAAE,EAAE,CAAC,CAAC,CAAC;;IAEhE,KAAK,KAAK;MAAE;QACR,IAAME,IAAC,GAAGpC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAItC,IAAI,CAAC,CAACwE,QAAQ,IAAI,EAAE,EAAE,CAAC,CAAC,EAAEE,IAAC,CAAC,YAAY,CAAC,CAAC;;;EAG7D,MAAM,IAAIC,KAAK,yBAAA7B,MAAA,CAAwB2B,MAAM,OAAG,CAAC;AACrD"},"metadata":{},"sourceType":"module"}