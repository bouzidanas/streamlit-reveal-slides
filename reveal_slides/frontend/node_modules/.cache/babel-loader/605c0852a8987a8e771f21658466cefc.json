{"ast":null,"code":"import _regeneratorRuntime from \"/home/anasbouzid/streamlit-reveal-slides/reveal_slides/frontend/node_modules/@babel/runtime/helpers/esm/regeneratorRuntime.js\";\nimport _asyncToGenerator from \"/home/anasbouzid/streamlit-reveal-slides/reveal_slides/frontend/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\nimport _construct from \"/home/anasbouzid/streamlit-reveal-slides/reveal_slides/frontend/node_modules/@babel/runtime/helpers/esm/construct.js\";\nimport _slicedToArray from \"/home/anasbouzid/streamlit-reveal-slides/reveal_slides/frontend/node_modules/@babel/runtime/helpers/esm/slicedToArray.js\";\nimport _toConsumableArray from \"/home/anasbouzid/streamlit-reveal-slides/reveal_slides/frontend/node_modules/@babel/runtime/helpers/esm/toConsumableArray.js\";\nimport _classCallCheck from \"/home/anasbouzid/streamlit-reveal-slides/reveal_slides/frontend/node_modules/@babel/runtime/helpers/esm/classCallCheck.js\";\nimport _createClass from \"/home/anasbouzid/streamlit-reveal-slides/reveal_slides/frontend/node_modules/@babel/runtime/helpers/esm/createClass.js\";\nimport _inherits from \"/home/anasbouzid/streamlit-reveal-slides/reveal_slides/frontend/node_modules/@babel/runtime/helpers/esm/inherits.js\";\nimport _createSuper from \"/home/anasbouzid/streamlit-reveal-slides/reveal_slides/frontend/node_modules/@babel/runtime/helpers/esm/createSuper.js\";\nimport _asyncIterator from \"/home/anasbouzid/streamlit-reveal-slides/reveal_slides/frontend/node_modules/@babel/runtime/helpers/esm/asyncIterator.js\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nimport { Column } from './column';\nimport { Schema } from './schema';\nimport { RecordBatch, _InternalEmptyPlaceholderRecordBatch } from './recordbatch';\nimport { RecordBatchReader } from './ipc/reader';\nimport { Struct } from './type';\nimport { selectColumnArgs, selectArgs } from './util/args';\nimport { isPromise, isIterable, isAsyncIterable } from './util/compat';\nimport { RecordBatchFileWriter, RecordBatchStreamWriter } from './ipc/writer';\nimport { distributeColumnsIntoRecordBatches, distributeVectorsIntoRecordBatches } from './util/recordbatch';\nimport { Chunked, StructVector } from './vector/index';\nexport var Table = /*#__PURE__*/function (_Chunked) {\n  _inherits(Table, _Chunked);\n  var _super = _createSuper(Table);\n  function Table() {\n    var _this;\n    _classCallCheck(this, Table);\n    var schema = null;\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n    if (args[0] instanceof Schema) {\n      schema = args.shift();\n    }\n    var chunks = selectArgs(RecordBatch, args);\n    if (!schema && !(schema = chunks[0] && chunks[0].schema)) {\n      throw new TypeError('Table must be initialized with a Schema or at least one RecordBatch');\n    }\n    chunks[0] || (chunks[0] = new _InternalEmptyPlaceholderRecordBatch(schema));\n    _this = _super.call(this, new Struct(schema.fields), chunks);\n    _this._schema = schema;\n    _this._chunks = chunks;\n    return _this;\n  }\n  /** @nocollapse */\n  _createClass(Table, [{\n    key: \"schema\",\n    get: function get() {\n      return this._schema;\n    }\n  }, {\n    key: \"length\",\n    get: function get() {\n      return this._length;\n    }\n  }, {\n    key: \"chunks\",\n    get: function get() {\n      return this._chunks;\n    }\n  }, {\n    key: \"numCols\",\n    get: function get() {\n      return this._numChildren;\n    }\n  }, {\n    key: \"clone\",\n    value: function clone() {\n      var chunks = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : this._chunks;\n      return new Table(this._schema, chunks);\n    }\n  }, {\n    key: \"getColumn\",\n    value: function getColumn(name) {\n      return this.getColumnAt(this.getColumnIndex(name));\n    }\n  }, {\n    key: \"getColumnAt\",\n    value: function getColumnAt(index) {\n      return this.getChildAt(index);\n    }\n  }, {\n    key: \"getColumnIndex\",\n    value: function getColumnIndex(name) {\n      return this._schema.fields.findIndex(function (f) {\n        return f.name === name;\n      });\n    }\n  }, {\n    key: \"getChildAt\",\n    value: function getChildAt(index) {\n      if (index < 0 || index >= this.numChildren) {\n        return null;\n      }\n      var field, child;\n      var fields = this._schema.fields;\n      var columns = this._children || (this._children = []);\n      if (child = columns[index]) {\n        return child;\n      }\n      if (field = fields[index]) {\n        var chunks = this._chunks.map(function (chunk) {\n          return chunk.getChildAt(index);\n        }).filter(function (vec) {\n          return vec != null;\n        });\n        if (chunks.length > 0) {\n          return columns[index] = new Column(field, chunks);\n        }\n      }\n      return null;\n    }\n    // @ts-ignore\n  }, {\n    key: \"serialize\",\n    value: function serialize() {\n      var encoding = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 'binary';\n      var stream = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n      var Writer = !stream ? RecordBatchFileWriter : RecordBatchStreamWriter;\n      return Writer.writeAll(this).toUint8Array(true);\n    }\n  }, {\n    key: \"count\",\n    value: function count() {\n      return this._length;\n    }\n  }, {\n    key: \"select\",\n    value: function select() {\n      var nameToIndex = this._schema.fields.reduce(function (m, f, i) {\n        return m.set(f.name, i);\n      }, new Map());\n      for (var _len2 = arguments.length, columnNames = new Array(_len2), _key2 = 0; _key2 < _len2; _key2++) {\n        columnNames[_key2] = arguments[_key2];\n      }\n      return this.selectAt.apply(this, _toConsumableArray(columnNames.map(function (columnName) {\n        return nameToIndex.get(columnName);\n      }).filter(function (x) {\n        return x > -1;\n      })));\n    }\n  }, {\n    key: \"selectAt\",\n    value: function selectAt() {\n      var _this$_schema;\n      for (var _len3 = arguments.length, columnIndices = new Array(_len3), _key3 = 0; _key3 < _len3; _key3++) {\n        columnIndices[_key3] = arguments[_key3];\n      }\n      var schema = (_this$_schema = this._schema).selectAt.apply(_this$_schema, columnIndices);\n      return new Table(schema, this._chunks.map(function (_ref) {\n        var length = _ref.length,\n          childData = _ref.data.childData;\n        return new RecordBatch(schema, length, columnIndices.map(function (i) {\n          return childData[i];\n        }).filter(Boolean));\n      }));\n    }\n  }, {\n    key: \"assign\",\n    value: function assign(other) {\n      var _this2 = this;\n      var fields = this._schema.fields;\n      var _other$schema$fields$ = other.schema.fields.reduce(function (memo, f2, newIdx) {\n          var _memo = _slicedToArray(memo, 2),\n            indices = _memo[0],\n            oldToNew = _memo[1];\n          var i = fields.findIndex(function (f) {\n            return f.name === f2.name;\n          });\n          ~i ? oldToNew[i] = newIdx : indices.push(newIdx);\n          return memo;\n        }, [[], []]),\n        _other$schema$fields$2 = _slicedToArray(_other$schema$fields$, 2),\n        indices = _other$schema$fields$2[0],\n        oldToNew = _other$schema$fields$2[1];\n      var schema = this._schema.assign(other.schema);\n      var columns = [].concat(_toConsumableArray(fields.map(function (_f, i, _fs) {\n        var j = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : oldToNew[i];\n        return j === undefined ? _this2.getColumnAt(i) : other.getColumnAt(j);\n      })), _toConsumableArray(indices.map(function (i) {\n        return other.getColumnAt(i);\n      }))).filter(Boolean);\n      return _construct(Table, _toConsumableArray(distributeVectorsIntoRecordBatches(schema, columns)));\n    }\n  }], [{\n    key: \"empty\",\n    value: function empty() {\n      var schema = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : new Schema([]);\n      return new Table(schema, []);\n    }\n    /** @nocollapse */\n  }, {\n    key: \"from\",\n    value: function from(input) {\n      if (!input) {\n        return Table.empty();\n      }\n      if (typeof input === 'object') {\n        var table = isIterable(input['values']) ? tableFromIterable(input) : isAsyncIterable(input['values']) ? tableFromAsyncIterable(input) : null;\n        if (table !== null) {\n          return table;\n        }\n      }\n      var reader = RecordBatchReader.from(input);\n      if (isPromise(reader)) {\n        return _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee() {\n          return _regeneratorRuntime().wrap(function _callee$(_context) {\n            while (1) switch (_context.prev = _context.next) {\n              case 0:\n                _context.t0 = Table;\n                _context.next = 3;\n                return reader;\n              case 3:\n                _context.t1 = _context.sent;\n                _context.next = 6;\n                return _context.t0.from.call(_context.t0, _context.t1);\n              case 6:\n                return _context.abrupt(\"return\", _context.sent);\n              case 7:\n              case \"end\":\n                return _context.stop();\n            }\n          }, _callee);\n        }))();\n      }\n      if (reader.isSync() && (reader = reader.open())) {\n        return !reader.schema ? Table.empty() : new Table(reader.schema, _toConsumableArray(reader));\n      }\n      return function () {\n        var _ref3 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee2(opening) {\n          var reader, schema, batches, _iteratorAbruptCompletion, _didIteratorError, _iteratorError, _iterator, _step, batch;\n          return _regeneratorRuntime().wrap(function _callee2$(_context2) {\n            while (1) switch (_context2.prev = _context2.next) {\n              case 0:\n                _context2.next = 2;\n                return opening;\n              case 2:\n                reader = _context2.sent;\n                schema = reader.schema;\n                batches = [];\n                if (!schema) {\n                  _context2.next = 35;\n                  break;\n                }\n                _iteratorAbruptCompletion = false;\n                _didIteratorError = false;\n                _context2.prev = 8;\n                _iterator = _asyncIterator(reader);\n              case 10:\n                _context2.next = 12;\n                return _iterator.next();\n              case 12:\n                if (!(_iteratorAbruptCompletion = !(_step = _context2.sent).done)) {\n                  _context2.next = 18;\n                  break;\n                }\n                batch = _step.value;\n                batches.push(batch);\n              case 15:\n                _iteratorAbruptCompletion = false;\n                _context2.next = 10;\n                break;\n              case 18:\n                _context2.next = 24;\n                break;\n              case 20:\n                _context2.prev = 20;\n                _context2.t0 = _context2[\"catch\"](8);\n                _didIteratorError = true;\n                _iteratorError = _context2.t0;\n              case 24:\n                _context2.prev = 24;\n                _context2.prev = 25;\n                if (!(_iteratorAbruptCompletion && _iterator.return != null)) {\n                  _context2.next = 29;\n                  break;\n                }\n                _context2.next = 29;\n                return _iterator.return();\n              case 29:\n                _context2.prev = 29;\n                if (!_didIteratorError) {\n                  _context2.next = 32;\n                  break;\n                }\n                throw _iteratorError;\n              case 32:\n                return _context2.finish(29);\n              case 33:\n                return _context2.finish(24);\n              case 34:\n                return _context2.abrupt(\"return\", new Table(schema, batches));\n              case 35:\n                return _context2.abrupt(\"return\", Table.empty());\n              case 36:\n              case \"end\":\n                return _context2.stop();\n            }\n          }, _callee2, null, [[8, 20, 24, 34], [25,, 29, 33]]);\n        }));\n        return function (_x) {\n          return _ref3.apply(this, arguments);\n        };\n      }()(reader.open());\n    }\n    /** @nocollapse */\n  }, {\n    key: \"fromAsync\",\n    value: function () {\n      var _fromAsync = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee3(source) {\n        return _regeneratorRuntime().wrap(function _callee3$(_context3) {\n          while (1) switch (_context3.prev = _context3.next) {\n            case 0:\n              _context3.next = 2;\n              return Table.from(source);\n            case 2:\n              return _context3.abrupt(\"return\", _context3.sent);\n            case 3:\n            case \"end\":\n              return _context3.stop();\n          }\n        }, _callee3);\n      }));\n      function fromAsync(_x2) {\n        return _fromAsync.apply(this, arguments);\n      }\n      return fromAsync;\n    }() /** @nocollapse */\n  }, {\n    key: \"fromStruct\",\n    value: function fromStruct(vector) {\n      return Table.new(vector.data.childData, vector.type.children);\n    }\n    /** @nocollapse */\n  }, {\n    key: \"new\",\n    value: function _new() {\n      for (var _len4 = arguments.length, cols = new Array(_len4), _key4 = 0; _key4 < _len4; _key4++) {\n        cols[_key4] = arguments[_key4];\n      }\n      return _construct(Table, _toConsumableArray(distributeColumnsIntoRecordBatches(selectColumnArgs(cols))));\n    }\n  }]);\n  return Table;\n}(Chunked);\nfunction tableFromIterable(input) {\n  var type = input.type;\n  if (type instanceof Struct) {\n    return Table.fromStruct(StructVector.from(input));\n  }\n  return null;\n}\nfunction tableFromAsyncIterable(input) {\n  var type = input.type;\n  if (type instanceof Struct) {\n    return StructVector.from(input).then(function (vector) {\n      return Table.fromStruct(vector);\n    });\n  }\n  return null;\n}","map":{"version":3,"names":["Column","Schema","RecordBatch","_InternalEmptyPlaceholderRecordBatch","RecordBatchReader","Struct","selectColumnArgs","selectArgs","isPromise","isIterable","isAsyncIterable","RecordBatchFileWriter","RecordBatchStreamWriter","distributeColumnsIntoRecordBatches","distributeVectorsIntoRecordBatches","Chunked","StructVector","Table","_Chunked","_inherits","_super","_createSuper","_this","_classCallCheck","schema","_len","arguments","length","args","Array","_key","shift","chunks","TypeError","call","fields","_schema","_chunks","_createClass","key","get","_length","_numChildren","value","clone","undefined","getColumn","name","getColumnAt","getColumnIndex","index","getChildAt","findIndex","f","numChildren","field","child","columns","_children","map","chunk","filter","vec","serialize","encoding","stream","Writer","writeAll","toUint8Array","count","select","nameToIndex","reduce","m","i","set","Map","_len2","columnNames","_key2","selectAt","apply","_toConsumableArray","columnName","x","_this$_schema","_len3","columnIndices","_key3","_ref","childData","data","Boolean","assign","other","_this2","_other$schema$fields$","memo","f2","newIdx","_memo","_slicedToArray","indices","oldToNew","push","_other$schema$fields$2","concat","_f","_fs","j","_construct","empty","from","input","table","tableFromIterable","tableFromAsyncIterable","reader","_asyncToGenerator","_regeneratorRuntime","mark","_callee","wrap","_callee$","_context","prev","next","t0","t1","sent","abrupt","stop","isSync","open","_ref3","_callee2","opening","batches","_iteratorAbruptCompletion","_didIteratorError","_iteratorError","_iterator","_step","batch","_callee2$","_context2","_asyncIterator","done","return","finish","_x","_fromAsync","_callee3","source","_callee3$","_context3","fromAsync","_x2","fromStruct","vector","new","type","children","_new","_len4","cols","_key4","then"],"sources":["table.ts"],"sourcesContent":["// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\nimport { Data } from './data';\nimport { Column } from './column';\nimport { Schema, Field } from './schema';\nimport { RecordBatch, _InternalEmptyPlaceholderRecordBatch } from './recordbatch';\nimport { DataFrame } from './compute/dataframe';\nimport { RecordBatchReader } from './ipc/reader';\nimport { DataType, RowLike, Struct } from './type';\nimport { selectColumnArgs, selectArgs } from './util/args';\nimport { Clonable, Sliceable, Applicative } from './vector';\nimport { isPromise, isIterable, isAsyncIterable } from './util/compat';\nimport { RecordBatchFileWriter, RecordBatchStreamWriter } from './ipc/writer';\nimport { distributeColumnsIntoRecordBatches, distributeVectorsIntoRecordBatches } from './util/recordbatch';\nimport { Vector, Chunked, StructVector, VectorBuilderOptions, VectorBuilderOptionsAsync } from './vector/index';\n\ntype VectorMap = { [key: string]: Vector };\ntype Fields<T extends { [key: string]: DataType }> = (keyof T)[] | Field<T[keyof T]>[];\ntype ChildData<T extends { [key: string]: DataType }> = Data<T[keyof T]>[] | Vector<T[keyof T]>[];\ntype Columns<T extends { [key: string]: DataType }> = Column<T[keyof T]>[] | Column<T[keyof T]>[][];\n\nexport interface Table<T extends { [key: string]: DataType } = any> {\n\n    get(index: number): Struct<T>['TValue'];\n    [Symbol.iterator](): IterableIterator<RowLike<T>>;\n\n    slice(begin?: number, end?: number): Table<T>;\n    concat(...others: Vector<Struct<T>>[]): Table<T>;\n    clone(chunks?: RecordBatch<T>[], offsets?: Uint32Array): Table<T>;\n\n    scan(next: import('./compute/dataframe').NextFunc, bind?: import('./compute/dataframe').BindFunc): void;\n    scanReverse(next: import('./compute/dataframe').NextFunc, bind?: import('./compute/dataframe').BindFunc): void;\n    countBy(name: import('./compute/predicate').Col | string): import('./compute/dataframe').CountByResult;\n    filter(predicate: import('./compute/predicate').Predicate): import('./compute/dataframe').FilteredDataFrame<T>;\n}\n\nexport class Table<T extends { [key: string]: DataType } = any>\n    extends Chunked<Struct<T>>\n    implements DataFrame<T>,\n               Clonable<Table<T>>,\n               Sliceable<Table<T>>,\n               Applicative<Struct<T>, Table<T>> {\n\n    /** @nocollapse */\n    public static empty<T extends { [key: string]: DataType } = {}>(schema = new Schema<T>([])) { return new Table<T>(schema, []); }\n\n    public static from(): Table<{}>;\n    public static from<T extends { [key: string]: DataType } = any>(source: RecordBatchReader<T>): Table<T>;\n    public static from<T extends { [key: string]: DataType } = any>(source: import('./ipc/reader').FromArg0): Table<T>;\n    public static from<T extends { [key: string]: DataType } = any>(source: import('./ipc/reader').FromArg2): Table<T>;\n    public static from<T extends { [key: string]: DataType } = any>(source: import('./ipc/reader').FromArg1): Promise<Table<T>>;\n    public static from<T extends { [key: string]: DataType } = any>(source: import('./ipc/reader').FromArg3): Promise<Table<T>>;\n    public static from<T extends { [key: string]: DataType } = any>(source: import('./ipc/reader').FromArg4): Promise<Table<T>>;\n    public static from<T extends { [key: string]: DataType } = any>(source: import('./ipc/reader').FromArg5): Promise<Table<T>>;\n    public static from<T extends { [key: string]: DataType } = any>(source: PromiseLike<RecordBatchReader<T>>): Promise<Table<T>>;\n    public static from<T extends { [key: string]: DataType } = any, TNull = any>(options: VectorBuilderOptions<Struct<T>, TNull>): Table<T>;\n    public static from<T extends { [key: string]: DataType } = any, TNull = any>(options: VectorBuilderOptionsAsync<Struct<T>, TNull>): Promise<Table<T>>;\n    /** @nocollapse */\n    public static from<T extends { [key: string]: DataType } = any, TNull = any>(input?: any) {\n\n        if (!input) { return Table.empty(); }\n\n        if (typeof input === 'object') {\n            let table = isIterable(input['values']) ? tableFromIterable<T, TNull>(input)\n                 : isAsyncIterable(input['values']) ? tableFromAsyncIterable<T, TNull>(input)\n                                                    : null;\n            if (table !== null) { return table; }\n        }\n\n        let reader = RecordBatchReader.from<T>(input) as RecordBatchReader<T> | Promise<RecordBatchReader<T>>;\n\n        if (isPromise<RecordBatchReader<T>>(reader)) {\n            return (async () => await Table.from(await reader))();\n        }\n        if (reader.isSync() && (reader = reader.open())) {\n            return !reader.schema ? Table.empty() : new Table<T>(reader.schema, [...reader]);\n        }\n        return (async (opening) => {\n            const reader = await opening;\n            const schema = reader.schema;\n            const batches: RecordBatch[] = [];\n            if (schema) {\n                for await (let batch of reader) {\n                    batches.push(batch);\n                }\n                return new Table<T>(schema, batches);\n            }\n            return Table.empty();\n        })(reader.open());\n    }\n\n    /** @nocollapse */\n    public static async fromAsync<T extends { [key: string]: DataType } = any>(source: import('./ipc/reader').FromArgs): Promise<Table<T>> {\n        return await Table.from<T>(source as any);\n    }\n\n    /** @nocollapse */\n    public static fromStruct<T extends { [key: string]: DataType } = any>(vector: Vector<Struct<T>>) {\n        return Table.new<T>(vector.data.childData as Data<T[keyof T]>[], vector.type.children);\n    }\n\n    /**\n     * @summary Create a new Table from a collection of Columns or Vectors,\n     * with an optional list of names or Fields.\n     *\n     *\n     * `Table.new` accepts an Object of\n     * Columns or Vectors, where the keys will be used as the field names\n     * for the Schema:\n     * ```ts\n     * const i32s = Int32Vector.from([1, 2, 3]);\n     * const f32s = Float32Vector.from([.1, .2, .3]);\n     * const table = Table.new({ i32: i32s, f32: f32s });\n     * assert(table.schema.fields[0].name === 'i32');\n     * ```\n     *\n     * It also accepts a a list of Vectors with an optional list of names or\n     * Fields for the resulting Schema. If the list is omitted or a name is\n     * missing, the numeric index of each Vector will be used as the name:\n     * ```ts\n     * const i32s = Int32Vector.from([1, 2, 3]);\n     * const f32s = Float32Vector.from([.1, .2, .3]);\n     * const table = Table.new([i32s, f32s], ['i32']);\n     * assert(table.schema.fields[0].name === 'i32');\n     * assert(table.schema.fields[1].name === '1');\n     * ```\n     *\n     * If the supplied arguments are Columns, `Table.new` will infer the Schema\n     * from the Columns:\n     * ```ts\n     * const i32s = Column.new('i32', Int32Vector.from([1, 2, 3]));\n     * const f32s = Column.new('f32', Float32Vector.from([.1, .2, .3]));\n     * const table = Table.new(i32s, f32s);\n     * assert(table.schema.fields[0].name === 'i32');\n     * assert(table.schema.fields[1].name === 'f32');\n     * ```\n     *\n     * If the supplied Vector or Column lengths are unequal, `Table.new` will\n     * extend the lengths of the shorter Columns, allocating additional bytes\n     * to represent the additional null slots. The memory required to allocate\n     * these additional bitmaps can be computed as:\n     * ```ts\n     * let additionalBytes = 0;\n     * for (let vec in shorter_vectors) {\n     *     additionalBytes += (((longestLength - vec.length) + 63) & ~63) >> 3;\n     * }\n     * ```\n     *\n     * For example, an additional null bitmap for one million null values would require\n     * 125,000 bytes (`((1e6 + 63) & ~63) >> 3`), or approx. `0.11MiB`\n     */\n    public static new<T extends { [key: string]: DataType } = any>(...columns: Columns<T>): Table<T>;\n    public static new<T extends VectorMap = any>(children: T): Table<{ [P in keyof T]: T[P]['type'] }>;\n    public static new<T extends { [key: string]: DataType } = any>(children: ChildData<T>, fields?: Fields<T>): Table<T>;\n    /** @nocollapse */\n    public static new(...cols: any[]) {\n        return new Table(...distributeColumnsIntoRecordBatches(selectColumnArgs(cols)));\n    }\n\n    constructor(batches: RecordBatch<T>[]);\n    constructor(...batches: RecordBatch<T>[]);\n    constructor(schema: Schema<T>, batches: RecordBatch<T>[]);\n    constructor(schema: Schema<T>, ...batches: RecordBatch<T>[]);\n    constructor(...args: any[]) {\n\n        let schema: Schema<T> = null!;\n\n        if (args[0] instanceof Schema) { schema = args.shift(); }\n\n        let chunks = selectArgs<RecordBatch<T>>(RecordBatch, args);\n\n        if (!schema && !(schema = chunks[0] && chunks[0].schema)) {\n            throw new TypeError('Table must be initialized with a Schema or at least one RecordBatch');\n        }\n\n        chunks[0] || (chunks[0] = new _InternalEmptyPlaceholderRecordBatch(schema));\n\n        super(new Struct(schema.fields), chunks);\n\n        this._schema = schema;\n        this._chunks = chunks;\n    }\n\n    protected _schema: Schema<T>;\n    // List of inner RecordBatches\n    protected _chunks: RecordBatch<T>[];\n    protected _children?: Column<T[keyof T]>[];\n\n    public get schema() { return this._schema; }\n    public get length() { return this._length; }\n    public get chunks() { return this._chunks; }\n    public get numCols() { return this._numChildren; }\n\n    public clone(chunks = this._chunks) {\n        return new Table<T>(this._schema, chunks);\n    }\n\n    public getColumn<R extends keyof T>(name: R): Column<T[R]> {\n        return this.getColumnAt(this.getColumnIndex(name)) as Column<T[R]>;\n    }\n    public getColumnAt<R extends DataType = any>(index: number): Column<R> | null {\n        return this.getChildAt(index);\n    }\n    public getColumnIndex<R extends keyof T>(name: R) {\n        return this._schema.fields.findIndex((f) => f.name === name);\n    }\n    public getChildAt<R extends DataType = any>(index: number): Column<R> | null {\n        if (index < 0 || index >= this.numChildren) { return null; }\n        let field: Field<R>, child: Column<R>;\n        const fields = (this._schema as Schema<any>).fields;\n        const columns = this._children || (this._children = []) as Column[];\n        if (child = columns[index]) { return child as Column<R>; }\n        if (field = fields[index]) {\n            const chunks = this._chunks\n                .map((chunk) => chunk.getChildAt<R>(index))\n                .filter((vec): vec is Vector<R> => vec != null);\n            if (chunks.length > 0) {\n                return (columns[index] = new Column<R>(field, chunks));\n            }\n        }\n        return null;\n    }\n\n    // @ts-ignore\n    public serialize(encoding = 'binary', stream = true) {\n        const Writer = !stream\n            ? RecordBatchFileWriter\n            : RecordBatchStreamWriter;\n        return Writer.writeAll(this).toUint8Array(true);\n    }\n    public count(): number {\n        return this._length;\n    }\n    public select<K extends keyof T = any>(...columnNames: K[]) {\n        const nameToIndex = this._schema.fields.reduce((m, f, i) => m.set(f.name as K, i), new Map<K, number>());\n        return this.selectAt(...columnNames.map((columnName) => nameToIndex.get(columnName)!).filter((x) => x > -1));\n    }\n    public selectAt<K extends T[keyof T] = any>(...columnIndices: number[]) {\n        const schema = this._schema.selectAt<K>(...columnIndices);\n        return new Table(schema, this._chunks.map(({ length, data: { childData } }) => {\n            return new RecordBatch(schema, length, columnIndices.map((i) => childData[i]).filter(Boolean));\n        }));\n    }\n    public assign<R extends { [key: string]: DataType } = any>(other: Table<R>) {\n\n        const fields = this._schema.fields;\n        const [indices, oldToNew] = other.schema.fields.reduce((memo, f2, newIdx) => {\n            const [indices, oldToNew] = memo;\n            const i = fields.findIndex((f) => f.name === f2.name);\n            ~i ? (oldToNew[i] = newIdx) : indices.push(newIdx);\n            return memo;\n        }, [[], []] as number[][]);\n\n        const schema = this._schema.assign(other.schema);\n        const columns = [\n            ...fields.map((_f, i, _fs, j = oldToNew[i]) =>\n                (j === undefined ? this.getColumnAt(i) : other.getColumnAt(j))!),\n            ...indices.map((i) => other.getColumnAt(i)!)\n        ].filter(Boolean) as Column<(T & R)[keyof T | keyof R]>[];\n\n        return new Table<T & R>(...distributeVectorsIntoRecordBatches<any>(schema, columns));\n    }\n}\n\nfunction tableFromIterable<T extends { [key: string]: DataType } = any, TNull = any>(input: VectorBuilderOptions<Struct<T>, TNull>) {\n    const { type } = input;\n    if (type instanceof Struct) {\n        return Table.fromStruct(StructVector.from(input as VectorBuilderOptions<Struct<T>, TNull>));\n    }\n    return null;\n}\n\nfunction tableFromAsyncIterable<T extends { [key: string]: DataType } = any, TNull = any>(input: VectorBuilderOptionsAsync<Struct<T>, TNull>) {\n    const { type } = input;\n    if (type instanceof Struct) {\n        return StructVector.from(input as VectorBuilderOptionsAsync<Struct<T>, TNull>).then((vector) => Table.fromStruct(vector));\n    }\n    return null;\n}\n"],"mappings":";;;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA,SAASA,MAAM,QAAQ,UAAU;AACjC,SAASC,MAAM,QAAe,UAAU;AACxC,SAASC,WAAW,EAAEC,oCAAoC,QAAQ,eAAe;AAEjF,SAASC,iBAAiB,QAAQ,cAAc;AAChD,SAA4BC,MAAM,QAAQ,QAAQ;AAClD,SAASC,gBAAgB,EAAEC,UAAU,QAAQ,aAAa;AAE1D,SAASC,SAAS,EAAEC,UAAU,EAAEC,eAAe,QAAQ,eAAe;AACtE,SAASC,qBAAqB,EAAEC,uBAAuB,QAAQ,cAAc;AAC7E,SAASC,kCAAkC,EAAEC,kCAAkC,QAAQ,oBAAoB;AAC3G,SAAiBC,OAAO,EAAEC,YAAY,QAAyD,gBAAgB;AAsB/G,WAAaC,KACT,0BAAAC,QAAA;EAAAC,SAAA,CAAAF,KAAA,EAAAC,QAAA;EAAA,IAAAE,MAAA,GAAAC,YAAA,CAAAJ,KAAA;EA8HA,SAAAA,MAAA,EAA0B;IAAA,IAAAK,KAAA;IAAAC,eAAA,OAAAN,KAAA;IAEtB,IAAIO,MAAM,GAAc,IAAK;IAAC,SAAAC,IAAA,GAAAC,SAAA,CAAAC,MAAA,EAFnBC,IAAW,OAAAC,KAAA,CAAAJ,IAAA,GAAAK,IAAA,MAAAA,IAAA,GAAAL,IAAA,EAAAK,IAAA;MAAXF,IAAW,CAAAE,IAAA,IAAAJ,SAAA,CAAAI,IAAA;IAAA;IAItB,IAAIF,IAAI,CAAC,CAAC,CAAC,YAAY3B,MAAM,EAAE;MAAEuB,MAAM,GAAGI,IAAI,CAACG,KAAK,EAAE;;IAEtD,IAAIC,MAAM,GAAGzB,UAAU,CAAiBL,WAAW,EAAE0B,IAAI,CAAC;IAE1D,IAAI,CAACJ,MAAM,IAAI,EAAEA,MAAM,GAAGQ,MAAM,CAAC,CAAC,CAAC,IAAIA,MAAM,CAAC,CAAC,CAAC,CAACR,MAAM,CAAC,EAAE;MACtD,MAAM,IAAIS,SAAS,CAAC,qEAAqE,CAAC;;IAG9FD,MAAM,CAAC,CAAC,CAAC,KAAKA,MAAM,CAAC,CAAC,CAAC,GAAG,IAAI7B,oCAAoC,CAACqB,MAAM,CAAC,CAAC;IAE3EF,KAAA,GAAAF,MAAA,CAAAc,IAAA,OAAM,IAAI7B,MAAM,CAACmB,MAAM,CAACW,MAAM,CAAC,EAAEH,MAAM;IAEvCV,KAAA,CAAKc,OAAO,GAAGZ,MAAM;IACrBF,KAAA,CAAKe,OAAO,GAAGL,MAAM;IAAC,OAAAV,KAAA;EAC1B;EA1IA;EAAAgB,YAAA,CAAArB,KAAA;IAAAsB,GAAA;IAAAC,GAAA,EAiJA,SAAAA,IAAA,EAAiB;MAAK,OAAO,IAAI,CAACJ,OAAO;IAAE;EAAC;IAAAG,GAAA;IAAAC,GAAA,EAC5C,SAAAA,IAAA,EAAiB;MAAK,OAAO,IAAI,CAACC,OAAO;IAAE;EAAC;IAAAF,GAAA;IAAAC,GAAA,EAC5C,SAAAA,IAAA,EAAiB;MAAK,OAAO,IAAI,CAACH,OAAO;IAAE;EAAC;IAAAE,GAAA;IAAAC,GAAA,EAC5C,SAAAA,IAAA,EAAkB;MAAK,OAAO,IAAI,CAACE,YAAY;IAAE;EAAC;IAAAH,GAAA;IAAAI,KAAA,EAE3C,SAAAC,MAAA,EAA2B;MAAA,IAArBZ,MAAM,GAAAN,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAmB,SAAA,GAAAnB,SAAA,MAAG,IAAI,CAACW,OAAO;MAC9B,OAAO,IAAIpB,KAAK,CAAI,IAAI,CAACmB,OAAO,EAAEJ,MAAM,CAAC;IAC7C;EAAC;IAAAO,GAAA;IAAAI,KAAA,EAEM,SAAAG,UAA6BC,IAAO;MACvC,OAAO,IAAI,CAACC,WAAW,CAAC,IAAI,CAACC,cAAc,CAACF,IAAI,CAAC,CAAiB;IACtE;EAAC;IAAAR,GAAA;IAAAI,KAAA,EACM,SAAAK,YAAsCE,KAAa;MACtD,OAAO,IAAI,CAACC,UAAU,CAACD,KAAK,CAAC;IACjC;EAAC;IAAAX,GAAA;IAAAI,KAAA,EACM,SAAAM,eAAkCF,IAAO;MAC5C,OAAO,IAAI,CAACX,OAAO,CAACD,MAAM,CAACiB,SAAS,CAAC,UAACC,CAAC;QAAA,OAAKA,CAAC,CAACN,IAAI,KAAKA,IAAI;MAAA,EAAC;IAChE;EAAC;IAAAR,GAAA;IAAAI,KAAA,EACM,SAAAQ,WAAqCD,KAAa;MACrD,IAAIA,KAAK,GAAG,CAAC,IAAIA,KAAK,IAAI,IAAI,CAACI,WAAW,EAAE;QAAE,OAAO,IAAI;;MACzD,IAAIC,KAAe,EAAEC,KAAgB;MACrC,IAAMrB,MAAM,GAAI,IAAI,CAACC,OAAuB,CAACD,MAAM;MACnD,IAAMsB,OAAO,GAAG,IAAI,CAACC,SAAS,KAAK,IAAI,CAACA,SAAS,GAAG,EAAE,CAAa;MACnE,IAAIF,KAAK,GAAGC,OAAO,CAACP,KAAK,CAAC,EAAE;QAAE,OAAOM,KAAkB;;MACvD,IAAID,KAAK,GAAGpB,MAAM,CAACe,KAAK,CAAC,EAAE;QACvB,IAAMlB,MAAM,GAAG,IAAI,CAACK,OAAO,CACtBsB,GAAG,CAAC,UAACC,KAAK;UAAA,OAAKA,KAAK,CAACT,UAAU,CAAID,KAAK,CAAC;QAAA,EAAC,CAC1CW,MAAM,CAAC,UAACC,GAAG;UAAA,OAAuBA,GAAG,IAAI,IAAI;QAAA,EAAC;QACnD,IAAI9B,MAAM,CAACL,MAAM,GAAG,CAAC,EAAE;UACnB,OAAQ8B,OAAO,CAACP,KAAK,CAAC,GAAG,IAAIlD,MAAM,CAAIuD,KAAK,EAAEvB,MAAM,CAAC;;;MAG7D,OAAO,IAAI;IACf;IAEA;EAAA;IAAAO,GAAA;IAAAI,KAAA,EACO,SAAAoB,UAAA,EAA4C;MAAA,IAAlCC,QAAQ,GAAAtC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAmB,SAAA,GAAAnB,SAAA,MAAG,QAAQ;MAAA,IAAEuC,MAAM,GAAAvC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAmB,SAAA,GAAAnB,SAAA,MAAG,IAAI;MAC/C,IAAMwC,MAAM,GAAG,CAACD,MAAM,GAChBtD,qBAAqB,GACrBC,uBAAuB;MAC7B,OAAOsD,MAAM,CAACC,QAAQ,CAAC,IAAI,CAAC,CAACC,YAAY,CAAC,IAAI,CAAC;IACnD;EAAC;IAAA7B,GAAA;IAAAI,KAAA,EACM,SAAA0B,MAAA,EAAK;MACR,OAAO,IAAI,CAAC5B,OAAO;IACvB;EAAC;IAAAF,GAAA;IAAAI,KAAA,EACM,SAAA2B,OAAA,EAAmD;MACtD,IAAMC,WAAW,GAAG,IAAI,CAACnC,OAAO,CAACD,MAAM,CAACqC,MAAM,CAAC,UAACC,CAAC,EAAEpB,CAAC,EAAEqB,CAAC;QAAA,OAAKD,CAAC,CAACE,GAAG,CAACtB,CAAC,CAACN,IAAS,EAAE2B,CAAC,CAAC;MAAA,GAAE,IAAIE,GAAG,EAAa,CAAC;MAAC,SAAAC,KAAA,GAAAnD,SAAA,CAAAC,MAAA,EADnEmD,WAAgB,OAAAjD,KAAA,CAAAgD,KAAA,GAAAE,KAAA,MAAAA,KAAA,GAAAF,KAAA,EAAAE,KAAA;QAAhBD,WAAgB,CAAAC,KAAA,IAAArD,SAAA,CAAAqD,KAAA;MAAA;MAEtD,OAAO,IAAI,CAACC,QAAQ,CAAAC,KAAA,CAAb,IAAI,EAAAC,kBAAA,CAAaJ,WAAW,CAACnB,GAAG,CAAC,UAACwB,UAAU;QAAA,OAAKZ,WAAW,CAAC/B,GAAG,CAAC2C,UAAU,CAAE;MAAA,EAAC,CAACtB,MAAM,CAAC,UAACuB,CAAC;QAAA,OAAKA,CAAC,GAAG,CAAC,CAAC;MAAA,EAAC,EAAC;IAChH;EAAC;IAAA7C,GAAA;IAAAI,KAAA,EACM,SAAAqC,SAAA,EAA+D;MAAA,IAAAK,aAAA;MAAA,SAAAC,KAAA,GAAA5D,SAAA,CAAAC,MAAA,EAAvB4D,aAAuB,OAAA1D,KAAA,CAAAyD,KAAA,GAAAE,KAAA,MAAAA,KAAA,GAAAF,KAAA,EAAAE,KAAA;QAAvBD,aAAuB,CAAAC,KAAA,IAAA9D,SAAA,CAAA8D,KAAA;MAAA;MAClE,IAAMhE,MAAM,GAAG,CAAA6D,aAAA,OAAI,CAACjD,OAAO,EAAC4C,QAAQ,CAAAC,KAAA,CAAAI,aAAA,EAAOE,aAAa,CAAC;MACzD,OAAO,IAAItE,KAAK,CAACO,MAAM,EAAE,IAAI,CAACa,OAAO,CAACsB,GAAG,CAAC,UAAA8B,IAAA,EAAoC;QAAA,IAAjC9D,MAAM,GAAA8D,IAAA,CAAN9D,MAAM;UAAU+D,SAAS,GAAAD,IAAA,CAAjBE,IAAI,CAAID,SAAS;QAClE,OAAO,IAAIxF,WAAW,CAACsB,MAAM,EAAEG,MAAM,EAAE4D,aAAa,CAAC5B,GAAG,CAAC,UAACe,CAAC;UAAA,OAAKgB,SAAS,CAAChB,CAAC,CAAC;QAAA,EAAC,CAACb,MAAM,CAAC+B,OAAO,CAAC,CAAC;MAClG,CAAC,CAAC,CAAC;IACP;EAAC;IAAArD,GAAA;IAAAI,KAAA,EACM,SAAAkD,OAAoDC,KAAe;MAAA,IAAAC,MAAA;MAEtE,IAAM5D,MAAM,GAAG,IAAI,CAACC,OAAO,CAACD,MAAM;MAClC,IAAA6D,qBAAA,GAA4BF,KAAK,CAACtE,MAAM,CAACW,MAAM,CAACqC,MAAM,CAAC,UAACyB,IAAI,EAAEC,EAAE,EAAEC,MAAM,EAAI;UACxE,IAAAC,KAAA,GAAAC,cAAA,CAA4BJ,IAAI;YAAzBK,OAAO,GAAAF,KAAA;YAAEG,QAAQ,GAAAH,KAAA;UACxB,IAAM1B,CAAC,GAAGvC,MAAM,CAACiB,SAAS,CAAC,UAACC,CAAC;YAAA,OAAKA,CAAC,CAACN,IAAI,KAAKmD,EAAE,CAACnD,IAAI;UAAA,EAAC;UACrD,CAAC2B,CAAC,GAAI6B,QAAQ,CAAC7B,CAAC,CAAC,GAAGyB,MAAM,GAAIG,OAAO,CAACE,IAAI,CAACL,MAAM,CAAC;UAClD,OAAOF,IAAI;QACf,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAe,CAAC;QAAAQ,sBAAA,GAAAJ,cAAA,CAAAL,qBAAA;QALnBM,OAAO,GAAAG,sBAAA;QAAEF,QAAQ,GAAAE,sBAAA;MAOxB,IAAMjF,MAAM,GAAG,IAAI,CAACY,OAAO,CAACyD,MAAM,CAACC,KAAK,CAACtE,MAAM,CAAC;MAChD,IAAMiC,OAAO,GAAG,GAAAiD,MAAA,CAAAxB,kBAAA,CACT/C,MAAM,CAACwB,GAAG,CAAC,UAACgD,EAAE,EAAEjC,CAAC,EAAEkC,GAAG;QAAA,IAAEC,CAAC,GAAAnF,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAmB,SAAA,GAAAnB,SAAA,MAAG6E,QAAQ,CAAC7B,CAAC,CAAC;QAAA,OACrCmC,CAAC,KAAKhE,SAAS,GAAGkD,MAAI,CAAC/C,WAAW,CAAC0B,CAAC,CAAC,GAAGoB,KAAK,CAAC9C,WAAW,CAAC6D,CAAC,CAAC;MAAA,CAAE,CAAC,GAAA3B,kBAAA,CACjEoB,OAAO,CAAC3C,GAAG,CAAC,UAACe,CAAC;QAAA,OAAKoB,KAAK,CAAC9C,WAAW,CAAC0B,CAAC,CAAE;MAAA,EAAC,GAC9Cb,MAAM,CAAC+B,OAAO,CAAyC;MAEzD,OAAAkB,UAAA,CAAW7F,KAAK,EAAAiE,kBAAA,CAAWpE,kCAAkC,CAAMU,MAAM,EAAEiC,OAAO,CAAC;IACvF;EAAC;IAAAlB,GAAA;IAAAI,KAAA,EAzNM,SAAAoE,MAAA,EAAmF;MAAA,IAA1BvF,MAAA,GAAAE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAmB,SAAA,GAAAnB,SAAA,MAAS,IAAIzB,MAAM,CAAI,EAAE,CAAC;MAAI,OAAO,IAAIgB,KAAK,CAAIO,MAAM,EAAE,EAAE,CAAC;IAAE;IAa/H;EAAA;IAAAe,GAAA;IAAAI,KAAA,EACO,SAAAqE,KAAsEC,KAAW;MAEpF,IAAI,CAACA,KAAK,EAAE;QAAE,OAAOhG,KAAK,CAAC8F,KAAK,EAAE;;MAElC,IAAI,OAAOE,KAAK,KAAK,QAAQ,EAAE;QAC3B,IAAIC,KAAK,GAAGzG,UAAU,CAACwG,KAAK,CAAC,QAAQ,CAAC,CAAC,GAAGE,iBAAiB,CAAWF,KAAK,CAAC,GACrEvG,eAAe,CAACuG,KAAK,CAAC,QAAQ,CAAC,CAAC,GAAGG,sBAAsB,CAAWH,KAAK,CAAC,GACvC,IAAI;QAC9C,IAAIC,KAAK,KAAK,IAAI,EAAE;UAAE,OAAOA,KAAK;;;MAGtC,IAAIG,MAAM,GAAGjH,iBAAiB,CAAC4G,IAAI,CAAIC,KAAK,CAAyD;MAErG,IAAIzG,SAAS,CAAuB6G,MAAM,CAAC,EAAE;QACzC,OAAOC,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CAAC,SAAAC,QAAA;UAAA,OAAAF,mBAAA,GAAAG,IAAA,UAAAC,SAAAC,QAAA;YAAA,kBAAAA,QAAA,CAAAC,IAAA,GAAAD,QAAA,CAAAE,IAAA;cAAA;gBAAAF,QAAA,CAAAG,EAAA,GAAkB9G,KAAK;gBAAA2G,QAAA,CAAAE,IAAA;gBAAA,OAAYT,MAAM;cAAA;gBAAAO,QAAA,CAAAI,EAAA,GAAAJ,QAAA,CAAAK,IAAA;gBAAAL,QAAA,CAAAE,IAAA;gBAAA,OAAAF,QAAA,CAAAG,EAAA,CAAjBf,IAAI,CAAA9E,IAAA,CAAA0F,QAAA,CAAAG,EAAA,EAAAH,QAAA,CAAAI,EAAA;cAAA;gBAAA,OAAAJ,QAAA,CAAAM,MAAA,WAAAN,QAAA,CAAAK,IAAA;cAAA;cAAA;gBAAA,OAAAL,QAAA,CAAAO,IAAA;YAAA;UAAA,GAAAV,OAAA;QAAA,CAAc,GAAC,CAAE;;MAEzD,IAAIJ,MAAM,CAACe,MAAM,EAAE,KAAKf,MAAM,GAAGA,MAAM,CAACgB,IAAI,EAAE,CAAC,EAAE;QAC7C,OAAO,CAAChB,MAAM,CAAC7F,MAAM,GAAGP,KAAK,CAAC8F,KAAK,EAAE,GAAG,IAAI9F,KAAK,CAAIoG,MAAM,CAAC7F,MAAM,EAAA0D,kBAAA,CAAMmC,MAAM,CAAC,CAAC;;MAEpF,OAAO;QAAA,IAAAiB,KAAA,GAAAhB,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CAAC,SAAAe,SAAOC,OAAO;UAAA,IAAAnB,MAAA,EAAA7F,MAAA,EAAAiH,OAAA,EAAAC,yBAAA,EAAAC,iBAAA,EAAAC,cAAA,EAAAC,SAAA,EAAAC,KAAA,EAAAC,KAAA;UAAA,OAAAxB,mBAAA,GAAAG,IAAA,UAAAsB,UAAAC,SAAA;YAAA,kBAAAA,SAAA,CAAApB,IAAA,GAAAoB,SAAA,CAAAnB,IAAA;cAAA;gBAAAmB,SAAA,CAAAnB,IAAA;gBAAA,OACGU,OAAO;cAAA;gBAAtBnB,MAAM,GAAA4B,SAAA,CAAAhB,IAAA;gBACNzG,MAAM,GAAG6F,MAAM,CAAC7F,MAAM;gBACtBiH,OAAO,GAAkB,EAAE;gBAAA,KAC7BjH,MAAM;kBAAAyH,SAAA,CAAAnB,IAAA;kBAAA;gBAAA;gBAAAY,yBAAA;gBAAAC,iBAAA;gBAAAM,SAAA,CAAApB,IAAA;gBAAAgB,SAAA,GAAAK,cAAA,CACkB7B,MAAM;cAAA;gBAAA4B,SAAA,CAAAnB,IAAA;gBAAA,OAAAe,SAAA,CAAAf,IAAA;cAAA;gBAAA,MAAAY,yBAAA,KAAAI,KAAA,GAAAG,SAAA,CAAAhB,IAAA,EAAAkB,IAAA;kBAAAF,SAAA,CAAAnB,IAAA;kBAAA;gBAAA;gBAAfiB,KAAK,GAAAD,KAAA,CAAAnG,KAAA;gBAChB8F,OAAO,CAACjC,IAAI,CAACuC,KAAK,CAAC;cAAC;gBAAAL,yBAAA;gBAAAO,SAAA,CAAAnB,IAAA;gBAAA;cAAA;gBAAAmB,SAAA,CAAAnB,IAAA;gBAAA;cAAA;gBAAAmB,SAAA,CAAApB,IAAA;gBAAAoB,SAAA,CAAAlB,EAAA,GAAAkB,SAAA;gBAAAN,iBAAA;gBAAAC,cAAA,GAAAK,SAAA,CAAAlB,EAAA;cAAA;gBAAAkB,SAAA,CAAApB,IAAA;gBAAAoB,SAAA,CAAApB,IAAA;gBAAA,MAAAa,yBAAA,IAAAG,SAAA,CAAAO,MAAA;kBAAAH,SAAA,CAAAnB,IAAA;kBAAA;gBAAA;gBAAAmB,SAAA,CAAAnB,IAAA;gBAAA,OAAAe,SAAA,CAAAO,MAAA;cAAA;gBAAAH,SAAA,CAAApB,IAAA;gBAAA,KAAAc,iBAAA;kBAAAM,SAAA,CAAAnB,IAAA;kBAAA;gBAAA;gBAAA,MAAAc,cAAA;cAAA;gBAAA,OAAAK,SAAA,CAAAI,MAAA;cAAA;gBAAA,OAAAJ,SAAA,CAAAI,MAAA;cAAA;gBAAA,OAAAJ,SAAA,CAAAf,MAAA,WAEjB,IAAIjH,KAAK,CAAIO,MAAM,EAAEiH,OAAO,CAAC;cAAA;gBAAA,OAAAQ,SAAA,CAAAf,MAAA,WAEjCjH,KAAK,CAAC8F,KAAK,EAAE;cAAA;cAAA;gBAAA,OAAAkC,SAAA,CAAAd,IAAA;YAAA;UAAA,GAAAI,QAAA;QAAA,CACvB;QAAA,iBAAAe,EAAA;UAAA,OAAAhB,KAAA,CAAArD,KAAA,OAAAvD,SAAA;QAAA;MAAA,IAAE2F,MAAM,CAACgB,IAAI,EAAE,CAAC;IACrB;IAEA;EAAA;IAAA9F,GAAA;IAAAI,KAAA;MAAA,IAAA4G,UAAA,GAAAjC,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CACO,SAAAgC,SAAoEC,MAAuC;QAAA,OAAAlC,mBAAA,GAAAG,IAAA,UAAAgC,UAAAC,SAAA;UAAA,kBAAAA,SAAA,CAAA9B,IAAA,GAAA8B,SAAA,CAAA7B,IAAA;YAAA;cAAA6B,SAAA,CAAA7B,IAAA;cAAA,OACjG7G,KAAK,CAAC+F,IAAI,CAAIyC,MAAa,CAAC;YAAA;cAAA,OAAAE,SAAA,CAAAzB,MAAA,WAAAyB,SAAA,CAAA1B,IAAA;YAAA;YAAA;cAAA,OAAA0B,SAAA,CAAAxB,IAAA;UAAA;QAAA,GAAAqB,QAAA;MAAA,CAC5C;MAAA,SAAAI,UAAAC,GAAA;QAAA,OAAAN,UAAA,CAAAtE,KAAA,OAAAvD,SAAA;MAAA;MAAA,OAAAkI,SAAA;IAAA,IAED;EAAA;IAAArH,GAAA;IAAAI,KAAA,EACO,SAAAmH,WAA+DC,MAAyB;MAC3F,OAAO9I,KAAK,CAAC+I,GAAG,CAAID,MAAM,CAACpE,IAAI,CAACD,SAA+B,EAAEqE,MAAM,CAACE,IAAI,CAACC,QAAQ,CAAC;IAC1F;IAuDA;EAAA;IAAA3H,GAAA;IAAAI,KAAA,EACO,SAAAwH,KAAA,EAAyB;MAAA,SAAAC,KAAA,GAAA1I,SAAA,CAAAC,MAAA,EAAX0I,IAAW,OAAAxI,KAAA,CAAAuI,KAAA,GAAAE,KAAA,MAAAA,KAAA,GAAAF,KAAA,EAAAE,KAAA;QAAXD,IAAW,CAAAC,KAAA,IAAA5I,SAAA,CAAA4I,KAAA;MAAA;MAC5B,OAAAxD,UAAA,CAAW7F,KAAK,EAAAiE,kBAAA,CAAIrE,kCAAkC,CAACP,gBAAgB,CAAC+J,IAAI,CAAC,CAAC;IAClF;EAAC;EAAA,OAAApJ,KAAA;AAAA,EAxHOF,OAAkB;AAmO9B,SAASoG,iBAAiBA,CAA2DF,KAA6C;EAC9H,IAAQgD,IAAI,GAAKhD,KAAK,CAAdgD,IAAI;EACZ,IAAIA,IAAI,YAAY5J,MAAM,EAAE;IACxB,OAAOY,KAAK,CAAC6I,UAAU,CAAC9I,YAAY,CAACgG,IAAI,CAACC,KAA+C,CAAC,CAAC;;EAE/F,OAAO,IAAI;AACf;AAEA,SAASG,sBAAsBA,CAA2DH,KAAkD;EACxI,IAAQgD,IAAI,GAAKhD,KAAK,CAAdgD,IAAI;EACZ,IAAIA,IAAI,YAAY5J,MAAM,EAAE;IACxB,OAAOW,YAAY,CAACgG,IAAI,CAACC,KAAoD,CAAC,CAACsD,IAAI,CAAC,UAACR,MAAM;MAAA,OAAK9I,KAAK,CAAC6I,UAAU,CAACC,MAAM,CAAC;IAAA,EAAC;;EAE7H,OAAO,IAAI;AACf"},"metadata":{},"sourceType":"module"}