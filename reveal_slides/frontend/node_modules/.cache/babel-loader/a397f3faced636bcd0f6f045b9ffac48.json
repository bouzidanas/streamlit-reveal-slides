{"ast":null,"code":"import _construct from \"/home/anasbouzid/streamlit/streamlit.io/streamlit-reveal-slides/reveal_slides/frontend/node_modules/@babel/runtime/helpers/esm/construct.js\";\nimport _toConsumableArray from \"/home/anasbouzid/streamlit/streamlit.io/streamlit-reveal-slides/reveal_slides/frontend/node_modules/@babel/runtime/helpers/esm/toConsumableArray.js\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nimport { Data } from '../data';\nimport { Schema } from '../schema';\nimport { Chunked } from '../vector/chunked';\nimport { RecordBatch } from '../recordbatch';\nvar noopBuf = new Uint8Array(0);\nvar nullBufs = function nullBufs(bitmapLength) {\n  return [noopBuf, noopBuf, new Uint8Array(bitmapLength), noopBuf];\n};\n/** @ignore */\nexport function ensureSameLengthData(schema, chunks) {\n  var batchLength = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : chunks.reduce(function (l, c) {\n    return Math.max(l, c.length);\n  }, 0);\n  var data;\n  var field;\n  var i = -1,\n    n = chunks.length;\n  var fields = _toConsumableArray(schema.fields);\n  var batchData = [];\n  var bitmapLength = (batchLength + 63 & ~63) >> 3;\n  while (++i < n) {\n    if ((data = chunks[i]) && data.length === batchLength) {\n      batchData[i] = data;\n    } else {\n      (field = fields[i]).nullable || (fields[i] = fields[i].clone({\n        nullable: true\n      }));\n      batchData[i] = data ? data._changeLengthAndBackfillNullBitmap(batchLength) : Data.new(field.type, 0, batchLength, batchLength, nullBufs(bitmapLength));\n    }\n  }\n  return [new Schema(fields), batchLength, batchData];\n}\n/** @ignore */\nexport function distributeColumnsIntoRecordBatches(columns) {\n  return distributeVectorsIntoRecordBatches(new Schema(columns.map(function (_ref) {\n    var field = _ref.field;\n    return field;\n  })), columns);\n}\n/** @ignore */\nexport function distributeVectorsIntoRecordBatches(schema, vecs) {\n  return uniformlyDistributeChunksAcrossRecordBatches(schema, vecs.map(function (v) {\n    return v instanceof Chunked ? v.chunks.map(function (c) {\n      return c.data;\n    }) : [v.data];\n  }));\n}\n/** @ignore */\nfunction uniformlyDistributeChunksAcrossRecordBatches(schema, columns) {\n  var fields = _toConsumableArray(schema.fields);\n  var batchArgs = [];\n  var memo = {\n    numBatches: columns.reduce(function (n, c) {\n      return Math.max(n, c.length);\n    }, 0)\n  };\n  var numBatches = 0,\n    batchLength = 0;\n  var i = -1,\n    numColumns = columns.length;\n  var child,\n    childData = [];\n  while (memo.numBatches-- > 0) {\n    for (batchLength = Number.POSITIVE_INFINITY, i = -1; ++i < numColumns;) {\n      childData[i] = child = columns[i].shift();\n      batchLength = Math.min(batchLength, child ? child.length : batchLength);\n    }\n    if (isFinite(batchLength)) {\n      childData = distributeChildData(fields, batchLength, childData, columns, memo);\n      if (batchLength > 0) {\n        batchArgs[numBatches++] = [batchLength, childData.slice()];\n      }\n    }\n  }\n  return [schema = new Schema(fields, schema.metadata), batchArgs.map(function (xs) {\n    return _construct(RecordBatch, [schema].concat(_toConsumableArray(xs)));\n  })];\n}\n/** @ignore */\nfunction distributeChildData(fields, batchLength, childData, columns, memo) {\n  var data;\n  var field;\n  var length = 0,\n    i = -1,\n    n = columns.length;\n  var bitmapLength = (batchLength + 63 & ~63) >> 3;\n  while (++i < n) {\n    if ((data = childData[i]) && (length = data.length) >= batchLength) {\n      if (length === batchLength) {\n        childData[i] = data;\n      } else {\n        childData[i] = data.slice(0, batchLength);\n        data = data.slice(batchLength, length - batchLength);\n        memo.numBatches = Math.max(memo.numBatches, columns[i].unshift(data));\n      }\n    } else {\n      (field = fields[i]).nullable || (fields[i] = field.clone({\n        nullable: true\n      }));\n      childData[i] = data ? data._changeLengthAndBackfillNullBitmap(batchLength) : Data.new(field.type, 0, batchLength, batchLength, nullBufs(bitmapLength));\n    }\n  }\n  return childData;\n}","map":{"version":3,"names":["Data","Schema","Chunked","RecordBatch","noopBuf","Uint8Array","nullBufs","bitmapLength","ensureSameLengthData","schema","chunks","batchLength","arguments","length","undefined","reduce","l","c","Math","max","data","field","i","n","fields","_toConsumableArray","batchData","nullable","clone","_changeLengthAndBackfillNullBitmap","new","type","distributeColumnsIntoRecordBatches","columns","distributeVectorsIntoRecordBatches","map","_ref","vecs","uniformlyDistributeChunksAcrossRecordBatches","v","batchArgs","memo","numBatches","numColumns","child","childData","Number","POSITIVE_INFINITY","shift","min","isFinite","distributeChildData","slice","metadata","xs","_construct","concat","unshift"],"sources":["util/recordbatch.ts"],"sourcesContent":["// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\nimport { Column } from '../column';\nimport { Vector } from '../vector';\nimport { DataType } from '../type';\nimport { Data, Buffers } from '../data';\nimport { Schema, Field } from '../schema';\nimport { Chunked } from '../vector/chunked';\nimport { RecordBatch } from '../recordbatch';\n\nconst noopBuf = new Uint8Array(0);\nconst nullBufs = (bitmapLength: number) => <unknown> [\n    noopBuf, noopBuf, new Uint8Array(bitmapLength), noopBuf\n] as Buffers<any>;\n\n/** @ignore */\nexport function ensureSameLengthData<T extends { [key: string]: DataType } = any>(\n    schema: Schema<T>,\n    chunks: Data<T[keyof T]>[],\n    batchLength = chunks.reduce((l, c) => Math.max(l, c.length), 0)\n) {\n    let data: Data<T[keyof T]>;\n    let field: Field<T[keyof T]>;\n    let i = -1, n = chunks.length;\n    const fields = [...schema.fields];\n    const batchData = [] as Data<T[keyof T]>[];\n    const bitmapLength = ((batchLength + 63) & ~63) >> 3;\n    while (++i < n) {\n        if ((data = chunks[i]) && data.length === batchLength) {\n            batchData[i] = data;\n        } else {\n            (field = fields[i]).nullable || (fields[i] = fields[i].clone({ nullable: true }) as Field<T[keyof T]>);\n            batchData[i] = data ? data._changeLengthAndBackfillNullBitmap(batchLength)\n                : Data.new(field.type, 0, batchLength, batchLength, nullBufs(bitmapLength)) as Data<T[keyof T]>;\n        }\n    }\n    return [new Schema<T>(fields), batchLength, batchData] as [Schema<T>, number, Data<T[keyof T]>[]];\n}\n\n/** @ignore */\nexport function distributeColumnsIntoRecordBatches<T extends { [key: string]: DataType } = any>(columns: Column<T[keyof T]>[]): [Schema<T>, RecordBatch<T>[]] {\n    return distributeVectorsIntoRecordBatches<T>(new Schema<T>(columns.map(({ field }) => field)), columns);\n}\n\n/** @ignore */\nexport function distributeVectorsIntoRecordBatches<T extends { [key: string]: DataType } = any>(schema: Schema<T>, vecs: (Vector<T[keyof T]> | Chunked<T[keyof T]>)[]): [Schema<T>, RecordBatch<T>[]] {\n    return uniformlyDistributeChunksAcrossRecordBatches<T>(schema, vecs.map((v) => v instanceof Chunked ? v.chunks.map((c) => c.data) : [v.data]));\n}\n\n/** @ignore */\nfunction uniformlyDistributeChunksAcrossRecordBatches<T extends { [key: string]: DataType } = any>(schema: Schema<T>, columns: Data<T[keyof T]>[][]): [Schema<T>, RecordBatch<T>[]] {\n\n    const fields = [...schema.fields];\n    const batchArgs = [] as [number, Data<T[keyof T]>[]][];\n    const memo = { numBatches: columns.reduce((n, c) => Math.max(n, c.length), 0) };\n\n    let numBatches = 0, batchLength = 0;\n    let i: number = -1, numColumns = columns.length;\n    let child: Data<T[keyof T]>, childData: Data<T[keyof T]>[] = [];\n\n    while (memo.numBatches-- > 0) {\n\n        for (batchLength = Number.POSITIVE_INFINITY, i = -1; ++i < numColumns;) {\n            childData[i] = child = columns[i].shift()!;\n            batchLength = Math.min(batchLength, child ? child.length : batchLength);\n        }\n\n        if (isFinite(batchLength)) {\n            childData = distributeChildData(fields, batchLength, childData, columns, memo);\n            if (batchLength > 0) {\n                batchArgs[numBatches++] = [batchLength, childData.slice()];\n            }\n        }\n    }\n    return [\n        schema = new Schema<T>(fields, schema.metadata),\n        batchArgs.map((xs) => new RecordBatch(schema, ...xs))\n    ];\n}\n\n/** @ignore */\nfunction distributeChildData<T extends { [key: string]: DataType } = any>(fields: Field<T[keyof T]>[], batchLength: number, childData: Data<T[keyof T]>[], columns: Data<T[keyof T]>[][], memo: { numBatches: number }) {\n    let data: Data<T[keyof T]>;\n    let field: Field<T[keyof T]>;\n    let length = 0, i = -1, n = columns.length;\n    const bitmapLength = ((batchLength + 63) & ~63) >> 3;\n    while (++i < n) {\n        if ((data = childData[i]) && ((length = data.length) >= batchLength)) {\n            if (length === batchLength) {\n                childData[i] = data;\n            } else {\n                childData[i] = data.slice(0, batchLength);\n                data = data.slice(batchLength, length - batchLength);\n                memo.numBatches = Math.max(memo.numBatches, columns[i].unshift(data));\n            }\n        } else {\n            (field = fields[i]).nullable || (fields[i] = field.clone({ nullable: true }) as Field<T[keyof T]>);\n            childData[i] = data ? data._changeLengthAndBackfillNullBitmap(batchLength)\n                : Data.new(field.type, 0, batchLength, batchLength, nullBufs(bitmapLength)) as Data<T[keyof T]>;\n        }\n    }\n    return childData;\n}\n"],"mappings":";;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAKA,SAASA,IAAI,QAAiB,SAAS;AACvC,SAASC,MAAM,QAAe,WAAW;AACzC,SAASC,OAAO,QAAQ,mBAAmB;AAC3C,SAASC,WAAW,QAAQ,gBAAgB;AAE5C,IAAMC,OAAO,GAAG,IAAIC,UAAU,CAAC,CAAC,CAAC;AACjC,IAAMC,QAAQ,GAAG,SAAXA,QAAQA,CAAIC,YAAoB;EAAA,OAAe,CACjDH,OAAO,EAAEA,OAAO,EAAE,IAAIC,UAAU,CAACE,YAAY,CAAC,EAAEH,OAAO,CAC1C;AAAA;AAEjB;AACA,OAAM,SAAUI,oBAAoBA,CAChCC,MAAiB,EACjBC,MAA0B,EACqC;EAAA,IAA/DC,WAAW,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAGF,MAAM,CAACK,MAAM,CAAC,UAACC,CAAC,EAAEC,CAAC;IAAA,OAAKC,IAAI,CAACC,GAAG,CAACH,CAAC,EAAEC,CAAC,CAACJ,MAAM,CAAC;EAAA,GAAE,CAAC,CAAC;EAE/D,IAAIO,IAAsB;EAC1B,IAAIC,KAAwB;EAC5B,IAAIC,CAAC,GAAG,CAAC,CAAC;IAAEC,CAAC,GAAGb,MAAM,CAACG,MAAM;EAC7B,IAAMW,MAAM,GAAAC,kBAAA,CAAOhB,MAAM,CAACe,MAAM,CAAC;EACjC,IAAME,SAAS,GAAG,EAAwB;EAC1C,IAAMnB,YAAY,GAAG,CAAEI,WAAW,GAAG,EAAE,GAAI,CAAC,EAAE,KAAK,CAAC;EACpD,OAAO,EAAEW,CAAC,GAAGC,CAAC,EAAE;IACZ,IAAI,CAACH,IAAI,GAAGV,MAAM,CAACY,CAAC,CAAC,KAAKF,IAAI,CAACP,MAAM,KAAKF,WAAW,EAAE;MACnDe,SAAS,CAACJ,CAAC,CAAC,GAAGF,IAAI;KACtB,MAAM;MACH,CAACC,KAAK,GAAGG,MAAM,CAACF,CAAC,CAAC,EAAEK,QAAQ,KAAKH,MAAM,CAACF,CAAC,CAAC,GAAGE,MAAM,CAACF,CAAC,CAAC,CAACM,KAAK,CAAC;QAAED,QAAQ,EAAE;MAAI,CAAE,CAAsB,CAAC;MACtGD,SAAS,CAACJ,CAAC,CAAC,GAAGF,IAAI,GAAGA,IAAI,CAACS,kCAAkC,CAAClB,WAAW,CAAC,GACpEX,IAAI,CAAC8B,GAAG,CAACT,KAAK,CAACU,IAAI,EAAE,CAAC,EAAEpB,WAAW,EAAEA,WAAW,EAAEL,QAAQ,CAACC,YAAY,CAAC,CAAqB;;;EAG3G,OAAO,CAAC,IAAIN,MAAM,CAAIuB,MAAM,CAAC,EAAEb,WAAW,EAAEe,SAAS,CAA4C;AACrG;AAEA;AACA,OAAM,SAAUM,kCAAkCA,CAA8CC,OAA6B;EACzH,OAAOC,kCAAkC,CAAI,IAAIjC,MAAM,CAAIgC,OAAO,CAACE,GAAG,CAAC,UAAAC,IAAA;IAAA,IAAGf,KAAK,GAAAe,IAAA,CAALf,KAAK;IAAA,OAAOA,KAAK;EAAA,EAAC,CAAC,EAAEY,OAAO,CAAC;AAC3G;AAEA;AACA,OAAM,SAAUC,kCAAkCA,CAA8CzB,MAAiB,EAAE4B,IAAkD;EACjK,OAAOC,4CAA4C,CAAI7B,MAAM,EAAE4B,IAAI,CAACF,GAAG,CAAC,UAACI,CAAC;IAAA,OAAKA,CAAC,YAAYrC,OAAO,GAAGqC,CAAC,CAAC7B,MAAM,CAACyB,GAAG,CAAC,UAAClB,CAAC;MAAA,OAAKA,CAAC,CAACG,IAAI;IAAA,EAAC,GAAG,CAACmB,CAAC,CAACnB,IAAI,CAAC;EAAA,EAAC,CAAC;AAClJ;AAEA;AACA,SAASkB,4CAA4CA,CAA8C7B,MAAiB,EAAEwB,OAA6B;EAE/I,IAAMT,MAAM,GAAAC,kBAAA,CAAOhB,MAAM,CAACe,MAAM,CAAC;EACjC,IAAMgB,SAAS,GAAG,EAAoC;EACtD,IAAMC,IAAI,GAAG;IAAEC,UAAU,EAAET,OAAO,CAAClB,MAAM,CAAC,UAACQ,CAAC,EAAEN,CAAC;MAAA,OAAKC,IAAI,CAACC,GAAG,CAACI,CAAC,EAAEN,CAAC,CAACJ,MAAM,CAAC;IAAA,GAAE,CAAC;EAAC,CAAE;EAE/E,IAAI6B,UAAU,GAAG,CAAC;IAAE/B,WAAW,GAAG,CAAC;EACnC,IAAIW,CAAC,GAAW,CAAC,CAAC;IAAEqB,UAAU,GAAGV,OAAO,CAACpB,MAAM;EAC/C,IAAI+B,KAAuB;IAAEC,SAAS,GAAuB,EAAE;EAE/D,OAAOJ,IAAI,CAACC,UAAU,EAAE,GAAG,CAAC,EAAE;IAE1B,KAAK/B,WAAW,GAAGmC,MAAM,CAACC,iBAAiB,EAAEzB,CAAC,GAAG,CAAC,CAAC,EAAE,EAAEA,CAAC,GAAGqB,UAAU,GAAG;MACpEE,SAAS,CAACvB,CAAC,CAAC,GAAGsB,KAAK,GAAGX,OAAO,CAACX,CAAC,CAAC,CAAC0B,KAAK,EAAG;MAC1CrC,WAAW,GAAGO,IAAI,CAAC+B,GAAG,CAACtC,WAAW,EAAEiC,KAAK,GAAGA,KAAK,CAAC/B,MAAM,GAAGF,WAAW,CAAC;;IAG3E,IAAIuC,QAAQ,CAACvC,WAAW,CAAC,EAAE;MACvBkC,SAAS,GAAGM,mBAAmB,CAAC3B,MAAM,EAAEb,WAAW,EAAEkC,SAAS,EAAEZ,OAAO,EAAEQ,IAAI,CAAC;MAC9E,IAAI9B,WAAW,GAAG,CAAC,EAAE;QACjB6B,SAAS,CAACE,UAAU,EAAE,CAAC,GAAG,CAAC/B,WAAW,EAAEkC,SAAS,CAACO,KAAK,EAAE,CAAC;;;;EAItE,OAAO,CACH3C,MAAM,GAAG,IAAIR,MAAM,CAAIuB,MAAM,EAAEf,MAAM,CAAC4C,QAAQ,CAAC,EAC/Cb,SAAS,CAACL,GAAG,CAAC,UAACmB,EAAE;IAAA,OAAAC,UAAA,CAASpD,WAAW,GAACM,MAAM,EAAA+C,MAAA,CAAA/B,kBAAA,CAAK6B,EAAE;EAAA,CAAC,CAAC,CACxD;AACL;AAEA;AACA,SAASH,mBAAmBA,CAA8C3B,MAA2B,EAAEb,WAAmB,EAAEkC,SAA6B,EAAEZ,OAA6B,EAAEQ,IAA4B;EAClN,IAAIrB,IAAsB;EAC1B,IAAIC,KAAwB;EAC5B,IAAIR,MAAM,GAAG,CAAC;IAAES,CAAC,GAAG,CAAC,CAAC;IAAEC,CAAC,GAAGU,OAAO,CAACpB,MAAM;EAC1C,IAAMN,YAAY,GAAG,CAAEI,WAAW,GAAG,EAAE,GAAI,CAAC,EAAE,KAAK,CAAC;EACpD,OAAO,EAAEW,CAAC,GAAGC,CAAC,EAAE;IACZ,IAAI,CAACH,IAAI,GAAGyB,SAAS,CAACvB,CAAC,CAAC,KAAM,CAACT,MAAM,GAAGO,IAAI,CAACP,MAAM,KAAKF,WAAY,EAAE;MAClE,IAAIE,MAAM,KAAKF,WAAW,EAAE;QACxBkC,SAAS,CAACvB,CAAC,CAAC,GAAGF,IAAI;OACtB,MAAM;QACHyB,SAAS,CAACvB,CAAC,CAAC,GAAGF,IAAI,CAACgC,KAAK,CAAC,CAAC,EAAEzC,WAAW,CAAC;QACzCS,IAAI,GAAGA,IAAI,CAACgC,KAAK,CAACzC,WAAW,EAAEE,MAAM,GAAGF,WAAW,CAAC;QACpD8B,IAAI,CAACC,UAAU,GAAGxB,IAAI,CAACC,GAAG,CAACsB,IAAI,CAACC,UAAU,EAAET,OAAO,CAACX,CAAC,CAAC,CAACmC,OAAO,CAACrC,IAAI,CAAC,CAAC;;KAE5E,MAAM;MACH,CAACC,KAAK,GAAGG,MAAM,CAACF,CAAC,CAAC,EAAEK,QAAQ,KAAKH,MAAM,CAACF,CAAC,CAAC,GAAGD,KAAK,CAACO,KAAK,CAAC;QAAED,QAAQ,EAAE;MAAI,CAAE,CAAsB,CAAC;MAClGkB,SAAS,CAACvB,CAAC,CAAC,GAAGF,IAAI,GAAGA,IAAI,CAACS,kCAAkC,CAAClB,WAAW,CAAC,GACpEX,IAAI,CAAC8B,GAAG,CAACT,KAAK,CAACU,IAAI,EAAE,CAAC,EAAEpB,WAAW,EAAEA,WAAW,EAAEL,QAAQ,CAACC,YAAY,CAAC,CAAqB;;;EAG3G,OAAOsC,SAAS;AACpB"},"metadata":{},"sourceType":"module"}